{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Fine Food Review Analysis using Logistic Regression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Objective : Given a dataset, find  \n",
    "    * optimal lambda using k-fold cross validation.\n",
    "    * optimal lambda using GridSearch and RandomSearch for L1 and L2 penalties.\n",
    "    * Sparsity using L1 penalty.\n",
    "    * Checking multicollinearity.\n",
    "    for all the feature vectorizations like Bag of Words(BOW), TF-IDF,Avg W2v and Avg TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using the SQLite Table to read data.\n",
    "con = sqlite3.connect('final.sqlite') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    307061\n",
      "negative     57110\n",
      "Name: Score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_sql_query(\"\"\"SELECT * FROM Reviews\"\"\", con)\n",
    "labels_count = data['Score'].value_counts()\n",
    "#labels = sorted_data['Score']\n",
    "print(labels_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364171,)\n",
      "(364171, 12)\n"
     ]
    }
   ],
   "source": [
    "# TIme based sorting\n",
    "sorted_data=data.sort_values('Time', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "labels = sorted_data['Score']\n",
    "print(labels.shape)\n",
    "print(sorted_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138706</td>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "      <td>b'witti littl book make son laugh loud recit c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>138683</td>\n",
       "      <td>150501</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AJ46FKXOVC7NR</td>\n",
       "      <td>Nicholas A Mesiano</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>940809600</td>\n",
       "      <td>This whole series is great way to spend time w...</td>\n",
       "      <td>I can remember seeing the show when it aired o...</td>\n",
       "      <td>b'rememb see show air televis year ago child s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>417839</td>\n",
       "      <td>451856</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AIUWLEQ1ADEG5</td>\n",
       "      <td>Elizabeth Medina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>944092800</td>\n",
       "      <td>Entertainingl Funny!</td>\n",
       "      <td>Beetlejuice is a well written movie ..... ever...</td>\n",
       "      <td>b'beetlejuic well written movi everyth excel a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>346055</td>\n",
       "      <td>374359</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A344SMIA5JECGM</td>\n",
       "      <td>Vincent P. Ross</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>944438400</td>\n",
       "      <td>A modern day fairy tale</td>\n",
       "      <td>A twist of rumplestiskin captured on film, sta...</td>\n",
       "      <td>b'twist rumplestiskin captur film star michael...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>417838</td>\n",
       "      <td>451855</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AJH6LUC1UT1ON</td>\n",
       "      <td>The Phantom of the Opera</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>946857600</td>\n",
       "      <td>FANTASTIC!</td>\n",
       "      <td>Beetlejuice is an excellent and funny movie. K...</td>\n",
       "      <td>b'beetlejuic excel funni movi keaton hilari wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      Id   ProductId          UserId               ProfileName  \\\n",
       "0    138706  150524  0006641040   ACITT7DI6IDDL           shari zychinski   \n",
       "30   138683  150501  0006641040   AJ46FKXOVC7NR        Nicholas A Mesiano   \n",
       "424  417839  451856  B00004CXX9   AIUWLEQ1ADEG5          Elizabeth Medina   \n",
       "330  346055  374359  B00004CI84  A344SMIA5JECGM           Vincent P. Ross   \n",
       "423  417838  451855  B00004CXX9   AJH6LUC1UT1ON  The Phantom of the Opera   \n",
       "\n",
       "     HelpfulnessNumerator  HelpfulnessDenominator     Score       Time  \\\n",
       "0                       0                       0  positive  939340800   \n",
       "30                      2                       2  positive  940809600   \n",
       "424                     0                       0  positive  944092800   \n",
       "330                     1                       2  positive  944438400   \n",
       "423                     0                       0  positive  946857600   \n",
       "\n",
       "                                               Summary  \\\n",
       "0                            EVERY book is educational   \n",
       "30   This whole series is great way to spend time w...   \n",
       "424                               Entertainingl Funny!   \n",
       "330                            A modern day fairy tale   \n",
       "423                                         FANTASTIC!   \n",
       "\n",
       "                                                  Text  \\\n",
       "0    this witty little book makes my son laugh at l...   \n",
       "30   I can remember seeing the show when it aired o...   \n",
       "424  Beetlejuice is a well written movie ..... ever...   \n",
       "330  A twist of rumplestiskin captured on film, sta...   \n",
       "423  Beetlejuice is an excellent and funny movie. K...   \n",
       "\n",
       "                                           CleanedText  \n",
       "0    b'witti littl book make son laugh loud recit c...  \n",
       "30   b'rememb see show air televis year ago child s...  \n",
       "424  b'beetlejuic well written movi everyth excel a...  \n",
       "330  b'twist rumplestiskin captur film star michael...  \n",
       "423  b'beetlejuic excel funni movi keaton hilari wa...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data.head()         # Time is in ascending order which means the dataset is of Time Based slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'witti littl book make son laugh loud recit car drive along alway sing refrain hes learn whale india droop love new word book introduc silli classic book will bet son still abl recit memori colleg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data['CleanedText'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 12)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "sample_data = sorted_data.sample(n=100000)\n",
    "print(sample_data.shape)\n",
    "sample_labels = sample_data['Score']\n",
    "print(sample_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334349</th>\n",
       "      <td>313505</td>\n",
       "      <td>339442</td>\n",
       "      <td>B005A1LJ04</td>\n",
       "      <td>A24O15MYDNLZBE</td>\n",
       "      <td>Lori Smart \"Amazon Queen\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1326844800</td>\n",
       "      <td>Sugar Free Margarita Mocktail</td>\n",
       "      <td>These Crystal Light Mocktails are fantastic su...</td>\n",
       "      <td>b'crystal light mocktail fantast summeri treat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320870</th>\n",
       "      <td>266335</td>\n",
       "      <td>288700</td>\n",
       "      <td>B004Q4AQDW</td>\n",
       "      <td>A7E85LH2I0TAP</td>\n",
       "      <td>a metaphysician \"of erudition\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1321056000</td>\n",
       "      <td>One of the best...</td>\n",
       "      <td>One of my 3 favorite, flavored black teas.  I ...</td>\n",
       "      <td>b'one favorit flavor black tea cant begin desc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118810</th>\n",
       "      <td>265412</td>\n",
       "      <td>287701</td>\n",
       "      <td>B000SARZ46</td>\n",
       "      <td>A1H8RBIVE73JSB</td>\n",
       "      <td>Happy mom</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>1238630400</td>\n",
       "      <td>YUMMY</td>\n",
       "      <td>My son has multiple allergies, he's allergic t...</td>\n",
       "      <td>b'son multipl allergi hes allerg wheat egg nut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133894</th>\n",
       "      <td>96036</td>\n",
       "      <td>104365</td>\n",
       "      <td>B000YSRK7E</td>\n",
       "      <td>AWH2AY17ZU7W2</td>\n",
       "      <td>Jesse Baynard</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1220486400</td>\n",
       "      <td>Very good tortilla chips</td>\n",
       "      <td>The taste of these is right between Tostitos M...</td>\n",
       "      <td>b'tast right tostito multigrain chip origin su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280016</th>\n",
       "      <td>360595</td>\n",
       "      <td>390004</td>\n",
       "      <td>B003PEKJK4</td>\n",
       "      <td>A3QODWMRMV3XNE</td>\n",
       "      <td>Joy O. Williams</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>positive</td>\n",
       "      <td>1317600000</td>\n",
       "      <td>Best. Cinnamon. Ever.</td>\n",
       "      <td>Though Kirkland's is not as good as some other...</td>\n",
       "      <td>b'though kirkland good vietnames cinnamon ive ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index      Id   ProductId          UserId  \\\n",
       "334349  313505  339442  B005A1LJ04  A24O15MYDNLZBE   \n",
       "320870  266335  288700  B004Q4AQDW   A7E85LH2I0TAP   \n",
       "118810  265412  287701  B000SARZ46  A1H8RBIVE73JSB   \n",
       "133894   96036  104365  B000YSRK7E   AWH2AY17ZU7W2   \n",
       "280016  360595  390004  B003PEKJK4  A3QODWMRMV3XNE   \n",
       "\n",
       "                           ProfileName  HelpfulnessNumerator  \\\n",
       "334349       Lori Smart \"Amazon Queen\"                     0   \n",
       "320870  a metaphysician \"of erudition\"                     0   \n",
       "118810                       Happy mom                     2   \n",
       "133894                   Jesse Baynard                     0   \n",
       "280016                 Joy O. Williams                     9   \n",
       "\n",
       "        HelpfulnessDenominator     Score        Time  \\\n",
       "334349                       0  positive  1326844800   \n",
       "320870                       0  positive  1321056000   \n",
       "118810                       2  positive  1238630400   \n",
       "133894                       0  positive  1220486400   \n",
       "280016                       9  positive  1317600000   \n",
       "\n",
       "                              Summary  \\\n",
       "334349  Sugar Free Margarita Mocktail   \n",
       "320870             One of the best...   \n",
       "118810                          YUMMY   \n",
       "133894       Very good tortilla chips   \n",
       "280016          Best. Cinnamon. Ever.   \n",
       "\n",
       "                                                     Text  \\\n",
       "334349  These Crystal Light Mocktails are fantastic su...   \n",
       "320870  One of my 3 favorite, flavored black teas.  I ...   \n",
       "118810  My son has multiple allergies, he's allergic t...   \n",
       "133894  The taste of these is right between Tostitos M...   \n",
       "280016  Though Kirkland's is not as good as some other...   \n",
       "\n",
       "                                              CleanedText  \n",
       "334349  b'crystal light mocktail fantast summeri treat...  \n",
       "320870  b'one favorit flavor black tea cant begin desc...  \n",
       "118810  b'son multipl allergi hes allerg wheat egg nut...  \n",
       "133894  b'tast right tostito multigrain chip origin su...  \n",
       "280016  b'though kirkland good vietnames cinnamon ive ...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer() #in scikit-learn\n",
    "final_counts = count_vect.fit_transform(sample_data['CleanedText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standardized_data = StandardScaler(with_mean=False).fit_transform(final_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 38380)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "print(standardized_data.shape)\n",
    "print(sample_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, CV and Test -  BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data set into train and test\n",
    "X_1, X_test, y_1, y_test = cross_validation.train_test_split(standardized_data, sample_labels, test_size=0.3, random_state=0)\n",
    "# split the train data set into cross validation train and cross validation test\n",
    "X_tr, X_cv, y_tr, y_cv = cross_validation.train_test_split(X_1, y_1, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90899973268789958, 0.89826515117084926, 0.8778775500191246, 0.8580205152734024, 0.84759203540532402, 0.84689797040773873, 0.84887770387594252]\n"
     ]
    }
   ],
   "source": [
    "C_Val = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "cv_scores = []\n",
    "for val in C_Val:\n",
    "    Log_reg = LogisticRegression(C=val)\n",
    "    scores = cross_val_score(Log_reg, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of lambda is 0.001000.\n"
     ]
    }
   ],
   "source": [
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "# determining best lambda\n",
    "optimal_lambda = C_Val[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal number of lambda is %f.' % optimal_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAETCAYAAABTM4NXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121312198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the misclassification error for each lambda is :  [ 0.091  0.102  0.122  0.142  0.152  0.153  0.151]\n"
     ]
    }
   ],
   "source": [
    "# plot misclassification error vs alpha \n",
    "plt.plot(C_Val, MSE)\n",
    "\n",
    "for xy in zip(C_Val, np.round(MSE,3)):\n",
    "    plt.annotate('(%s, %s)' % xy, xy=xy, textcoords='data')\n",
    "\n",
    "plt.xlabel('Number of lambda points')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.title('MSE')\n",
    "plt.show()\n",
    "\n",
    "print(\"the misclassification error for each lambda is : \", np.round(MSE,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the Logistic Regression for C = 0.001000 is 91.183333%\n"
     ]
    }
   ],
   "source": [
    "# instantiate learning model k = optimal_k\n",
    "optimal_lambda = 0.001000\n",
    "log_reg_optimal = LogisticRegression(C=optimal_lambda)\n",
    "\n",
    "# fitting the model\n",
    "log_reg_optimal.fit(X_tr, y_tr)\n",
    "\n",
    "# predict the response\n",
    "pred = log_reg_optimal.predict(X_test)\n",
    "\n",
    "# evaluate accuracy\n",
    "acc = accuracy_score(y_test, pred) * 100\n",
    "print('\\nThe accuracy of the Logistic Regression for C = %f is %f%%' % (optimal_lambda, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch - BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model = GridSearchCV(LogisticRegression(), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model.fit(X_tr, y_tr)\n",
    "print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896666666667\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used GridSearchCV with L2 regularizer is 0.0001 and the accuracy is 89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_grid_l1 = GridSearchCV(LogisticRegression(penalty='l1',n_jobs=-1), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_grid_l1.fit(X_tr, y_tr)\n",
    "print(model_grid_l1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9085\n"
     ]
    }
   ],
   "source": [
    "print(model_grid_l1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used GridSearchCV with L1 regularizer is 0.0001 and the accuracy is 90.85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSearchCV - BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16351342,  0.52477133,  0.68842066,  0.64301038,  0.7576488 ,\n",
       "        0.68562934,  0.81814153,  0.73435129,  0.87159898,  0.7791563 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu, sigma = 0, 1\n",
    "s = np.random.normal(mu, sigma, 10)\n",
    "#print(s)\n",
    "from scipy.stats import uniform\n",
    "uniform.rvs(size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.0025899498542613086, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "tuned_parameters = {'C': uniform.rvs(size=10)}\n",
    "model_rand_l2 = RandomizedSearchCV(LogisticRegression(), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_rand_l2.fit(X_tr, y_tr)\n",
    "print(model_rand_l2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905333333333\n"
     ]
    }
   ],
   "source": [
    "print(model_rand_l2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used RandomSearchCV with L2 regularizer is 0.0025 and the accuracy is 90.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "tuned_parameters = {'C': uniform.rvs(size=10)}\n",
    "model_rand_l1 = RandomizedSearchCV(LogisticRegression(), tuned_parameters, scoring = 'accuracy', cv=5,n_jobs=-1)\n",
    "model_rand_l1.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.07652106455941643, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(model_rand_l1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.879366666667\n"
     ]
    }
   ],
   "source": [
    "print(model_rand_l1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used RandomSearchCV with L1 regularizer is 0.076 and the accuracy is 87.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsity with L1 BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.906233333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "clf = LogisticRegression(C=0.1, penalty='l1');\n",
    "clf.fit(X_tr, y_tr);\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8342\n"
     ]
    }
   ],
   "source": [
    "w = clf.coef_\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * The error rate is 10% when lambda is 0.1 and the number of non zero elements are 8342."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.876933333333\n",
      "non zero 10184\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1, penalty='l1');\n",
    "clf.fit(X_tr, y_tr);\n",
    "print('accuracy',clf.score(X_test,y_test))\n",
    "w = clf.coef_\n",
    "print('non zero', np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * The error rate is almost 13% when lambda is 1 and the number of non zero elements are 10184."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847233333333\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=100, penalty='l1');\n",
    "clf.fit(X_tr, y_tr);\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13921\n"
     ]
    }
   ],
   "source": [
    "w = clf.coef_\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * The error rate is almost 16% when lambda is 100 and the number of non zero elements are 13921.\n",
    "    * Clearly the error rate is increasing with the increase of lambda. Therefore the performance of the model decrease with the increase in lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Multicollinearity - BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Training the matrix afer adding the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05093885]\n"
     ]
    }
   ],
   "source": [
    "# Adding Noise to the matrix\n",
    "mu, sigma = 0, 0.1\n",
    "s = np.random.normal(mu, sigma, 1)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_matrix = standardized_data*s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data set into train and test\n",
    "X_1_bow, X_test_bow, y_1_bow, y_test_bow = cross_validation.train_test_split(noise_matrix, sample_labels, test_size=0.3, random_state=0)\n",
    "# split the train data set into cross validation train and cross validation test\n",
    "X_tr_bow, X_cv_bow, y_tr_bow, y_cv_bow = cross_validation.train_test_split(X_1_bow, y_1_bow, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the Logistic Regression after adding noise to the data for C = 0.001000 is 84.630000%\n"
     ]
    }
   ],
   "source": [
    "# instantiate learning model k = optimal_k\n",
    "optimal_lambda_multi = 0.001000 # taken from the above outcome from train,cv and test\n",
    "log_reg_mutli = LogisticRegression(C=optimal_lambda_multi) \n",
    "\n",
    "# fitting the model\n",
    "log_reg_mutli.fit(X_tr_bow, y_tr_bow)\n",
    "\n",
    "# predict the response\n",
    "pred = log_reg_mutli.predict(X_test_bow)\n",
    "\n",
    "# evaluate accuracy\n",
    "acc_multi = accuracy_score(y_test_bow, pred) * 100\n",
    "print('\\nThe accuracy of the Logistic Regression after adding noise to the data for C = %f is %f%%' % (optimal_lambda_multi, acc_multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 38380)\n",
      "[[ 0.001678    0.          0.         ...,  0.00230258  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "weight_multi = log_reg_mutli.coef_ # weights with  noise\n",
    "print(weight_multi.shape)\n",
    "print(weight_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 38380)\n",
      "[[ 0.00108222  0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Weights from the original matrix which is not added any noise\n",
    "original_weights = log_reg_optimal.coef_ # original weights with no noise\n",
    "print(original_weights.shape)\n",
    "print(original_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00059578  0.          0.          0.          0.00182784  0.0019195\n",
      "  0.00264413  0.0019195   0.00250729  0.00243956]\n"
     ]
    }
   ],
   "source": [
    "diffs = weight_multi - original_weights\n",
    "print(diffs.flatten()[:10])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * There is no much difference in weights after adding the noise. We can say that Bag of words technique is not affecting by multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance - BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38380,)\n",
      "[14416 19589  3116 ...,  8348 21975 38379]\n"
     ]
    }
   ],
   "source": [
    "abs_weights = np.abs(original_weights)\n",
    "weights_np = np.asarray(abs_weights).flatten()\n",
    "print(weights_np.shape)\n",
    "# get the sorting indices\n",
    "sorted_index = np.argsort(weights_np)[::-1]\n",
    "print(sorted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42384026  0.34710108  0.2762774  ...,  0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# check if the sorting indices are correct\n",
    "#flatten_abs_weigths = abs_weights.flatten()\n",
    "print(weights_np[sorted_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14416 19589  3116 14101  9341  8692 24935 11331 11831 22592]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get the index of the top-10 features\n",
    "top_10 = sorted_index[:10]\n",
    "top_f = np.asarray(top_10)\n",
    "print(top_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['great' 'love' 'best' 'good' 'disappoint' 'delici' 'perfect' 'excel'\n",
      " 'favorit' 'nice']\n"
     ]
    }
   ],
   "source": [
    "# get the names of the top 2 most important features\n",
    "feature_names = count_vect.get_feature_names()\n",
    "#print(feature_names[top_2])\n",
    "f = np.asarray(feature_names)\n",
    "print(f[top_f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 61762)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,1))\n",
    "final_tf_idf = tf_idf_vect.fit_transform(sample_data['Text'].values)\n",
    "print(final_tf_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 61762)\n"
     ]
    }
   ],
   "source": [
    "standardized_data_tf = StandardScaler(with_mean=False).fit_transform(final_tf_idf)\n",
    "print(standardized_data_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train,CV,Test - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data set into train and test\n",
    "X_1_tf, X_test_tf, y_1_tf, y_test_tf = cross_validation.train_test_split(standardized_data_tf, sample_labels, test_size=0.3, random_state=0)\n",
    "# split the train data set into cross validation train and cross validation test\n",
    "X_tr_tf, X_cv_tf, y_tr_tf, y_cv_tf = cross_validation.train_test_split(X_1_tf, y_1_tf, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90134681473110179, 0.88316310318829072, 0.86122431443275449, 0.84442827469165527, 0.83542842015911101, 0.83338758709805583, 0.83293862415064512]\n"
     ]
    }
   ],
   "source": [
    "C_Val = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "cv_scores_tf_idf = []\n",
    "for val in C_Val:\n",
    "    Log_reg_tf_idf = LogisticRegression(C=val)\n",
    "    scores_tf = cross_val_score(Log_reg_tf_idf, X_tr_tf, y_tr_tf, cv=10, scoring='accuracy')\n",
    "    cv_scores_tf_idf.append(scores_tf.mean())\n",
    "print(cv_scores_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of alpha is 1000.\n"
     ]
    }
   ],
   "source": [
    "# changing to misclassification error\n",
    "MSE_tf = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_aplha_tf = C_Val[MSE_tf.index(min(MSE_tf))]\n",
    "print('\\nThe optimal number of alpha is %d.' % optimal_aplha_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFlCAYAAADBIxOqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123fe22e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the misclassification error for each alpha is :  [ 0.156  0.156  0.155  0.105  0.083  0.079  0.078]\n"
     ]
    }
   ],
   "source": [
    "# plot misclassification error vs alpha \n",
    "plt.plot(C_Val, MSE_tf)\n",
    "\n",
    "for xy in zip(C_Val, np.round(MSE_tf,3)):\n",
    "    plt.annotate('(%s, %s)' % xy, xy=xy, textcoords='data')\n",
    "\n",
    "plt.xlabel('Number of aplha points')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.title('MSE')\n",
    "plt.show()\n",
    "\n",
    "print(\"the misclassification error for each alpha is : \", np.round(MSE_tf,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the Logistic Regression for C = 1000.000000 is 83.273333%\n"
     ]
    }
   ],
   "source": [
    "# instantiate learning model k = optimal_k\n",
    "optimal_aplha_tf=1000\n",
    "log_reg_optimal_tf = LogisticRegression(C=optimal_aplha_tf)\n",
    "\n",
    "# fitting the model\n",
    "log_reg_optimal_tf.fit(X_tr_tf, y_tr_tf)\n",
    "\n",
    "# predict the response\n",
    "pred_tf = log_reg_optimal_tf.predict(X_test_tf)\n",
    "\n",
    "# evaluate accuracy\n",
    "acc_tf = accuracy_score(y_test_tf, pred_tf) * 100\n",
    "print('\\nThe accuracy of the Logistic Regression for C = %f is %f%%' % (optimal_aplha_tf, acc_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_tf = GridSearchCV(LogisticRegression(), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_tf.fit(X_tr_tf, y_tr_tf)\n",
    "print(model_tf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916433333333\n"
     ]
    }
   ],
   "source": [
    "print(model_tf.score(X_test_tf, y_test_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used GridSearchCV with L2 regularizer is 1 and the accuracy is 91.64%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_tf_l1 = GridSearchCV(LogisticRegression(penalty='l1'), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_tf_l1.fit(X_tr_tf, y_tr_tf)\n",
    "print(model_tf_l1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916633333333\n"
     ]
    }
   ],
   "source": [
    "print(model_tf_l1.score(X_test_tf, y_test_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used GridSearchCV with L1 regularizer is 1 and the accuracy is 91.66% (slight increase in accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSearchCV TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.91361595715910737, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "tuned_parameters = {'C': uniform.rvs(size=10)}\n",
    "model_rand_l2_tf = RandomizedSearchCV(LogisticRegression(n_jobs=-1), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_rand_l2_tf.fit(X_tr_tf, y_tr_tf)\n",
    "print(model_rand_l2_tf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9157\n"
     ]
    }
   ],
   "source": [
    "print(model_rand_l2_tf.score(X_test_tf, y_test_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used RandomSearchCV with L2 regularizer is 0.91 and the accuracy is 91.57%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.96431769798190548, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=-1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "tuned_parameters = {'C': uniform.rvs(size=10)}\n",
    "model_rand_l1_tf = RandomizedSearchCV(LogisticRegression(penalty='l1',n_jobs=-1), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_rand_l1_tf.fit(X_tr_tf, y_tr_tf)\n",
    "print(model_rand_l1_tf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916466666667\n"
     ]
    }
   ],
   "source": [
    "print(model_rand_l1_tf.score(X_test_tf, y_test_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used RandomSearchCV with L1 regularizer is 1 and the accuracy is 91.64% (slight increase in accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsity with L1 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.885\n",
      "sparsity 133\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "clf_1_tf = LogisticRegression(C=0.1, penalty='l1');\n",
    "clf_1_tf.fit(X_tr_tf, y_tr_tf);\n",
    "print('acc',clf_1_tf.score(X_test_tf,y_test_tf))\n",
    "w_1_tf = clf_1_tf.coef_\n",
    "print('sparsity',np.count_nonzero(w_1_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * The error rate is 11.5% when lambda is 0.1 and the number of non zero elements are 133."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.916633333333\n",
      "sparsity 1098\n"
     ]
    }
   ],
   "source": [
    "clf_2_tf = LogisticRegression(C=1, penalty='l1');\n",
    "clf_2_tf.fit(X_tr_tf, y_tr_tf);\n",
    "print('acc',clf_2_tf.score(X_test_tf,y_test_tf))\n",
    "w_2_tf = clf_2_tf.coef_\n",
    "print('sparsity',np.count_nonzero(w_2_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * The error rate is 8.4% when lambda is 1 and the number of non zero elements are 1098."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8788\n",
      "sparsity 9246\n"
     ]
    }
   ],
   "source": [
    "clf_3_tf = LogisticRegression(C=100, penalty='l1');\n",
    "clf_3_tf.fit(X_tr_tf, y_tr_tf);\n",
    "print('acc',clf_3_tf.score(X_test_tf,y_test_tf))\n",
    "w_3_tf = clf_3_tf.coef_\n",
    "print('sparsity',np.count_nonzero(w_3_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * The error rate is 12.2% when lambda is 100 and the number of non zero elements are 9246."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicollinearity TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05013082]\n"
     ]
    }
   ],
   "source": [
    "# Adding Noise to the matrix\n",
    "mu, sigma = 0, 0.1\n",
    "s = np.random.normal(mu, sigma, 1)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_matrix_tf = standardized_data_tf*s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data set into train and test\n",
    "X_1_tf_mul, X_test_tf_mul, y_1_tf_mul, y_test_tf_mul = cross_validation.train_test_split(noise_matrix_tf, sample_labels, test_size=0.3, random_state=0)\n",
    "# split the train data set into cross validation train and cross validation test\n",
    "X_tr_tf_mul, X_cv_tf_mul, y_tr_tf_mul, y_cv_tf_mul = cross_validation.train_test_split(X_1_tf_mul, y_1_tf_mul, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the Logistic Regression for C = 1000.000000 is 87.400000%\n"
     ]
    }
   ],
   "source": [
    "# instantiate learning model k = optimal_k\n",
    "optimal_aplha_tf=1000\n",
    "log_reg_optimal_tf_mul = LogisticRegression(C=optimal_aplha_tf)\n",
    "\n",
    "# fitting the model\n",
    "log_reg_optimal_tf_mul.fit(X_tr_tf_mul, y_tr_tf_mul)\n",
    "\n",
    "# predict the response\n",
    "pred_tf_mul = log_reg_optimal_tf_mul.predict(X_test_tf_mul)\n",
    "\n",
    "# evaluate accuracy\n",
    "acc_tf_mul = accuracy_score(y_test_tf_mul, pred_tf_mul) * 100\n",
    "print('\\nThe accuracy of the Logistic Regression for C = %f is %f%%' % (optimal_aplha_tf, acc_tf_mul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 38380)\n",
      "[[ 0.3548621   0.          0.         ...,  0.05026341  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "weight_multi_tf = log_reg_optimal_tf_mul.coef_ # weights with  noise\n",
    "print(weight_multi_tf.shape)\n",
    "print(weight_multi_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 38380)\n",
      "[[-0.00901837  0.          0.         ...,  0.00143564  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Weights from the original matrix which is not added any noise\n",
    "original_weights_tf = log_reg_optimal_tf.coef_ # original weights with no noise\n",
    "print(original_weights_tf.shape)\n",
    "print(original_weights_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.36388047  0.          0.          0.          0.35698101  0.02554674\n",
      "  0.27296997  0.02554674  0.08481837  0.08355967]\n"
     ]
    }
   ],
   "source": [
    "diffs_tf = weight_multi_tf - original_weights_tf\n",
    "print(diffs_tf.flatten()[:10])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * There is no much difference in weights after adding the noise. We can say that TF-IDF technique is not affecting by multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38380,)\n",
      "[19589  8728  3116 ..., 24401  9678 38379]\n"
     ]
    }
   ],
   "source": [
    "#original_weights_tf_abs = np.abs(original_weights_tf)\n",
    "abs_weights_tf = np.abs(original_weights_tf)\n",
    "weights_np_tf = np.asarray(abs_weights_tf).flatten()\n",
    "print(weights_np_tf.shape)\n",
    "# get the sorting indices\n",
    "sorted_index_tf = np.argsort(weights_np_tf)[::-1]\n",
    "print(sorted_index_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.36188783  7.90683988  7.74112125 ...,  0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# check if the sorting indices are correct\n",
    "print(weights_np_tf[sorted_index_tf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19589  8728  3116 14416   319 11331 24935 38114 30088  8692]\n"
     ]
    }
   ],
   "source": [
    "# get the index of the top-10 features\n",
    "top_10 = sorted_index_tf[:10]\n",
    "top_f = np.asarray(top_10)\n",
    "print(top_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love' 'delight' 'best' 'great' 'addict' 'excel' 'perfect' 'yum' 'shes'\n",
      " 'delici']\n"
     ]
    }
   ],
   "source": [
    "# get the names of the top 2 most important features\n",
    "feature_names_tf = tf_idf_vect.get_feature_names()\n",
    "#print(feature_names[top_2])\n",
    "tf = np.asarray(feature_names_tf)\n",
    "print(tf[top_f])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    " * I took one gram in tf-idf and the reason is to reduce the importance of the most occuring words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x11a36a470>\n"
     ]
    }
   ],
   "source": [
    "# Using Google News Word2Vectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76640123"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "# Train your own Word2Vec model using your own text corpus\n",
    "import gensim\n",
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in sample_data['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent.append(filtered_sentence)\n",
    "print(len(list_of_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These Crystal Light Mocktails are fantastic summery treats for grown ups! So many of the sugar free flavored drinks are not aimed at adults, but these are great! You can't beat the taste of citrus to cool off, and the Margarita mix is perfect for warm days. It was actually very good as a mixer with a shot of tequila in it,too!\n",
      "*****************************************************************\n",
      "['these', 'crystal', 'light', 'mocktails', 'are', 'fantastic', 'summery', 'treats', 'for', 'grown', 'ups', 'so', 'many', 'of', 'the', 'sugar', 'free', 'flavored', 'drinks', 'are', 'not', 'aimed', 'at', 'adults', 'but', 'these', 'are', 'great', 'you', 'cant', 'beat', 'the', 'taste', 'of', 'citrus', 'to', 'cool', 'off', 'and', 'the', 'margarita', 'mix', 'is', 'perfect', 'for', 'warm', 'days', 'it', 'was', 'actually', 'very', 'good', 'as', 'a', 'mixer', 'with', 'a', 'shot', 'of', 'tequila', 'in', 'it', 'too']\n"
     ]
    }
   ],
   "source": [
    "print(sample_data['Text'].values[0])\n",
    "print(\"*****************************************************************\")\n",
    "print(list_of_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.word2vec.Word2Vec"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=5,size=50, workers=4)\n",
    "type(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19157\n"
     ]
    }
   ],
   "source": [
    "words = list(w2v_model.wv.vocab)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "50\n",
      "['these', 'crystal', 'light', 'mocktails', 'are', 'fantastic', 'summery', 'treats', 'for', 'grown', 'ups', 'so', 'many', 'of', 'the', 'sugar', 'free', 'flavored', 'drinks', 'are', 'not', 'aimed', 'at', 'adults', 'but', 'these', 'are', 'great', 'you', 'cant', 'beat', 'the', 'taste', 'of', 'citrus', 'to', 'cool', 'off', 'and', 'the', 'margarita', 'mix', 'is', 'perfect', 'for', 'warm', 'days', 'it', 'was', 'actually', 'very', 'good', 'as', 'a', 'mixer', 'with', 'a', 'shot', 'of', 'tequila', 'in', 'it', 'too']\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in list_of_sent: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))\n",
    "print(len(sent_vectors[0]))\n",
    "print(list_of_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.44188607 -0.11082012  0.11923695 -0.39371548 -0.01757231  0.55770447\n",
      "  0.31380234 -0.60181747 -0.10743466  0.22502994 -0.59566127  0.27098435\n",
      "  0.04081101 -0.13775745 -0.5128596   0.75088135  0.60063419  0.54239213\n",
      "  0.11818313 -0.58889848 -0.27934573  0.1439522   0.56386373  1.11674491\n",
      " -0.42911389  0.41811838  0.67825835  0.28803299  0.35926605  0.59986197\n",
      " -0.63473861 -0.26303549  0.0506224   0.15325701 -0.05400344 -0.22297534\n",
      "  0.11594248 -0.45334876  0.15019477  0.32380784 -0.48239108 -0.28310504\n",
      "  0.344402    0.96474976 -0.62155364 -0.29880266 -0.26324255  0.32983154\n",
      " -0.25016528 -1.00039061]\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(sent_vectors[0])\n",
    "print(len(sent_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train,CV,Test - AvgW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data set into train and test\n",
    "X_1_w2v, X_test_w2v, y_1_w2v, y_test_w2v = cross_validation.train_test_split(sent_vectors, sample_labels, test_size=0.3, random_state=0)\n",
    "\n",
    "# split the train data set into cross validation train and cross validation test\n",
    "X_tr_w2v, X_cv_w2v, y_tr_w2v, y_cv_w2v = cross_validation.train_test_split(X_1_w2v, y_1_w2v, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85269383933734932, 0.87687731369071409, 0.88106090816495208, 0.88169358207208359, 0.88134666411188056, 0.88124463162031719, 0.88134667244004361]\n"
     ]
    }
   ],
   "source": [
    "C_Val = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "cv_scores_w2v = []\n",
    "for val in C_Val:\n",
    "    Log_reg_w2v = LogisticRegression(C=val)\n",
    "    scores_w2v = cross_val_score(Log_reg_w2v, X_tr_w2v, y_tr_w2v, cv=10, scoring='accuracy')\n",
    "    cv_scores_w2v.append(scores_w2v.mean())\n",
    "print(cv_scores_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of alpha is 1.\n"
     ]
    }
   ],
   "source": [
    "# changing to misclassification error\n",
    "MSE_w2v = [1 - x for x in cv_scores_w2v]\n",
    "\n",
    "# determining best k\n",
    "optimal_aplha_w2v = C_Val[MSE_w2v.index(min(MSE_w2v))]\n",
    "print('\\nThe optimal number of alpha is %d.' % optimal_aplha_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAFlCAYAAADMPWPtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBBCiKzxH8jRPCKz1MQQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x292d2ae48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the misclassification error for each alpha is :  [ 0.147  0.123  0.119  0.118  0.119  0.119  0.119]\n"
     ]
    }
   ],
   "source": [
    "# plot misclassification error vs alpha \n",
    "plt.plot(C_Val, MSE_w2v)\n",
    "\n",
    "for xy in zip(C_Val, np.round(MSE_w2v,3)):\n",
    "    plt.annotate('(%s, %s)' % xy, xy=xy, textcoords='data')\n",
    "\n",
    "plt.xlabel('Number of aplha points')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.title('MSE')\n",
    "plt.show()\n",
    "\n",
    "print(\"the misclassification error for each alpha is : \", np.round(MSE_w2v,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the Logistic Regression for C = 1.000000 is 88.406667%\n"
     ]
    }
   ],
   "source": [
    "# instantiate learning model k = optimal_k\n",
    "optimal_aplha_w2v=1\n",
    "log_reg_optimal_w2v = LogisticRegression(C=optimal_aplha_w2v)\n",
    "\n",
    "# fitting the model\n",
    "log_reg_optimal_w2v.fit(X_tr_w2v, y_tr_w2v)\n",
    "\n",
    "# predict the response\n",
    "pred_w2v = log_reg_optimal_w2v.predict(X_test_w2v)\n",
    "\n",
    "# evaluate accuracy\n",
    "acc_w2v = accuracy_score(y_test_w2v, pred_w2v) * 100\n",
    "print('\\nThe accuracy of the Logistic Regression for C = %f is %f%%' % (optimal_aplha_w2v, acc_w2v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch Avg W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_w2v_l2 = GridSearchCV(LogisticRegression(n_jobs=-1), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_w2v_l2.fit(X_tr_w2v, y_tr_w2v)\n",
    "print(model_w2v_l2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.883666666667\n"
     ]
    }
   ],
   "source": [
    "print(model_w2v_l2.score(X_test_w2v, y_test_w2v))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used GridSearchCV with L2 regularizer is 10000 and the accuracy is 88.36%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_w2v_l1 = GridSearchCV(LogisticRegression(penalty='l1',n_jobs=-1), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_w2v_l1.fit(X_tr_w2v, y_tr_w2v)\n",
    "print(model_w2v_l1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.883266666667\n"
     ]
    }
   ],
   "source": [
    "print(model_w2v_l1.score(X_test_w2v, y_test_w2v))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used GridSearchCV with L1 regularizer is 1 and the accuracy is 88.32%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSearchCV Avg W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.80559108708562166, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "tuned_parameters = {'C': uniform.rvs(size=10)}\n",
    "model_rand_l2_w2v = RandomizedSearchCV(LogisticRegression(n_jobs=-1), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_rand_l2_w2v.fit(X_tr_w2v, y_tr_w2v)\n",
    "print(model_rand_l2_w2v.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.883566666667\n"
     ]
    }
   ],
   "source": [
    "print(model_rand_l2_w2v.score(X_test_w2v, y_test_w2v))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used RandomSearchCV with L2 regularizer is 0.80 and the accuracy is 88.356%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.91760039713185504, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=-1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "tuned_parameters = {'C': uniform.rvs(size=10)}\n",
    "model_rand_l1_w2v = RandomizedSearchCV(LogisticRegression(penalty='l1',n_jobs=-1), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_rand_l1_w2v.fit(X_tr_w2v, y_tr_w2v)\n",
    "print(model_rand_l1_w2v.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.883533333333\n"
     ]
    }
   ],
   "source": [
    "print(model_rand_l1_w2v.score(X_test_w2v, y_test_w2v))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used RandomSearchCV with L1 regularizer is 0.91 and the accuracy is 88.353%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Sparsity with L1 Avg W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8842\n",
      "sparsity 48\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "clf_1_w2v = LogisticRegression(C=0.1, penalty='l1');\n",
    "clf_1_w2v.fit(X_tr_w2v, y_tr_w2v);\n",
    "print('acc',clf_1_w2v.score(X_test_w2v,y_test_w2v))\n",
    "w_1_w2v = clf_1_w2v.coef_\n",
    "print('sparsity',np.count_nonzero(w_1_w2v))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * The error rate is 11.58% when lambda is 0.1 and the number of non zero elements are 48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.883333333333\n",
      "sparsity 50\n"
     ]
    }
   ],
   "source": [
    "clf_2_w2v = LogisticRegression(C=1, penalty='l1');\n",
    "clf_2_w2v.fit(X_tr_w2v, y_tr_w2v);\n",
    "print('acc',clf_2_w2v.score(X_test_w2v,y_test_w2v))\n",
    "w_2_w2v = clf_2_w2v.coef_\n",
    "print('sparsity',np.count_nonzero(w_2_w2v))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * The error rate is 11.67% when lambda is 1 and the number of non zero elements are 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8837\n",
      "sparsity 50\n"
     ]
    }
   ],
   "source": [
    "clf_3_w2v = LogisticRegression(C=100, penalty='l1');\n",
    "clf_3_w2v.fit(X_tr_w2v, y_tr_w2v);\n",
    "print('acc',clf_3_w2v.score(X_test_w2v,y_test_w2v))\n",
    "w_3_w2v = clf_3_w2v.coef_\n",
    "print('sparsity',np.count_nonzero(w_3_w2v))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * The error rate is 11.62% when lambda is 100 and the number of non zero elements are 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicollinearity Avg W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05373827]\n"
     ]
    }
   ],
   "source": [
    "# Adding Noise to the matrix\n",
    "mu, sigma = 0, 0.1\n",
    "s = np.random.normal(mu, sigma, 1)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.44188607, -0.11082012,  0.11923695, -0.39371548, -0.01757231,\n",
       "        0.55770447,  0.31380234, -0.60181747, -0.10743466,  0.22502994,\n",
       "       -0.59566127,  0.27098435,  0.04081101, -0.13775745, -0.5128596 ,\n",
       "        0.75088135,  0.60063419,  0.54239213,  0.11818313, -0.58889848,\n",
       "       -0.27934573,  0.1439522 ,  0.56386373,  1.11674491, -0.42911389,\n",
       "        0.41811838,  0.67825835,  0.28803299,  0.35926605,  0.59986197,\n",
       "       -0.63473861, -0.26303549,  0.0506224 ,  0.15325701, -0.05400344,\n",
       "       -0.22297534,  0.11594248, -0.45334876,  0.15019477,  0.32380784,\n",
       "       -0.48239108, -0.28310504,  0.344402  ,  0.96474976, -0.62155364,\n",
       "       -0.29880266, -0.26324255,  0.32983154, -0.25016528, -1.00039061])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_vector_w2v = [i * 0.05373827 for i in sent_vectors] # adding noise to the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02374619, -0.00595528,  0.00640759, -0.02115759, -0.00094431,\n",
       "        0.02997007,  0.01686319, -0.03234063, -0.00577335,  0.01209272,\n",
       "       -0.03200981,  0.01456223,  0.00219311, -0.00740285, -0.02756019,\n",
       "        0.04035106,  0.03227704,  0.02914721,  0.00635096, -0.03164639,\n",
       "       -0.01501156,  0.00773574,  0.03030106,  0.06001194, -0.02305984,\n",
       "        0.02246896,  0.03644843,  0.01547839,  0.01930634,  0.03223554,\n",
       "       -0.03410976, -0.01413507,  0.00272036,  0.00823577, -0.00290205,\n",
       "       -0.01198231,  0.00623055, -0.02436218,  0.00807121,  0.01740087,\n",
       "       -0.02592286, -0.01521358,  0.01850757,  0.05184398, -0.03340122,\n",
       "       -0.01605714, -0.0141462 ,  0.01772458, -0.01344345, -0.05375926])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_vector_w2v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data set into train and test\n",
    "X_1_w2v_mul, X_test_w2v_mul, y_1_w2v_mul, y_test_w2v_mul = cross_validation.train_test_split(noise_vector_w2v, sample_labels, test_size=0.3, random_state=0)\n",
    "\n",
    "# split the train data set into cross validation train and cross validation test\n",
    "X_tr_w2v_mul, X_cv_w2v_mul, y_tr_w2v_mul, y_cv_w2v_mul = cross_validation.train_test_split(X_1_w2v_mul, y_1_w2v_mul, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the Logistic Regression for C = 1.000000 is 87.250000%\n"
     ]
    }
   ],
   "source": [
    "# instantiate learning model k = optimal_k\n",
    "optimal_aplha_w2v=1\n",
    "log_reg_optimal_w2v_mul = LogisticRegression(C=optimal_aplha_w2v)\n",
    "\n",
    "# fitting the model\n",
    "log_reg_optimal_w2v_mul.fit(X_tr_w2v_mul, y_tr_w2v_mul)\n",
    "\n",
    "# predict the response\n",
    "pred_w2v_mul = log_reg_optimal_w2v_mul.predict(X_test_w2v_mul)\n",
    "\n",
    "# evaluate accuracy\n",
    "acc_w2v_mul = accuracy_score(y_test_w2v_mul, pred_w2v_mul) * 100\n",
    "print('\\nThe accuracy of the Logistic Regression for C = %f is %f%%' % (optimal_aplha_w2v, acc_w2v_mul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50)\n",
      "[[ -0.52946628   0.4325097    7.99115862   1.55398753   6.86266371\n",
      "   11.31293541  -0.60481716  11.61001414  -6.80116669  12.6609681\n",
      "    0.07297742   4.39949113   4.67354836  -8.18519988   1.7537636\n",
      "   -5.13268185  -5.94731944   7.87460556  -6.29573609  -3.84760909\n",
      "   -7.78393785  -0.44889409   2.80500272   8.96015192 -11.14312205\n",
      "   -3.93184652 -14.29838931  -2.74497703   4.19137862   1.89534764\n",
      "   -5.41071046   1.03903327  -6.41208814  -5.47661896  -8.04055982\n",
      "   -7.05250795  -3.36681588 -10.79145235  -0.62962113  -6.65838344\n",
      "   -9.65503403  -4.97194237  -7.37102992   8.97198237  -5.03058574\n",
      "   -6.16988719  -4.72276893  14.56186151  14.19053535  -6.05073668]]\n"
     ]
    }
   ],
   "source": [
    "weight_multi_w2v = log_reg_optimal_w2v_mul.coef_ # weights with  noise\n",
    "print(weight_multi_w2v.shape)\n",
    "print(weight_multi_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50)\n",
      "[[-0.03579462 -0.63082425  1.06866886 -0.29352074  1.40347648  0.61565648\n",
      "  -1.22930168  0.28273635 -1.66991331  1.17700618  0.19146611  0.09689499\n",
      "   0.45792826 -1.01784316  1.33165397 -0.71172841 -0.2545565   1.1073005\n",
      "  -0.61779611 -0.94173729 -0.08242883 -0.54201401  0.65707153  0.96581498\n",
      "  -1.17252775 -0.95380022 -1.81057379  0.88824571  0.24305723  0.67671295\n",
      "  -0.41579838  0.32646834 -0.16144522 -0.07150347 -0.51035837 -0.75892702\n",
      "   0.46683699 -0.42670059  0.2004345  -1.32867807 -1.43807692 -0.74951363\n",
      "   0.1768732   0.86734874 -1.05419953 -1.03278689 -0.850341    2.27049878\n",
      "   0.85318335 -1.32756014]]\n"
     ]
    }
   ],
   "source": [
    "# Weights from the original matrix which is not added any noise\n",
    "original_weights_w2v = log_reg_optimal_w2v.coef_ # original weights with no noise\n",
    "print(original_weights_w2v.shape)\n",
    "print(original_weights_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.49367167   1.06333394   6.92248976   1.84750827   5.45918723\n",
      "  10.69727894   0.62448452  11.32727779  -5.13125337  11.48396192\n",
      "  -0.11848869   4.30259614   4.21562011  -7.16735672   0.42210963\n",
      "  -4.42095344  -5.69276294   6.76730506  -5.67793998  -2.9058718 ]\n"
     ]
    }
   ],
   "source": [
    "diffs_w2v = weight_multi_w2v - original_weights_w2v\n",
    "print(diffs_w2v.flatten()[:20])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "   * I observe the some high difference between the noised and original weights. There is a multicollinearity exists among the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avg TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TF-IDF weighted Word2Vec\n",
    "tfidf_feat = tf_idf_vect.get_feature_names() # tfidf words/col-names\n",
    "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n",
    "\n",
    "tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in list_of_sent: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            # obtain the tf_idfidf of a word in a sentence/review\n",
    "            tfidf = final_tf_idf[row, tfidf_feat.index(word)]\n",
    "            sent_vec = sent_vec + (vec * tfidf)\n",
    "            weight_sum = weight_sum + tfidf\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors.append(sent_vec)\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51174193 -0.31839725 -0.0983731  -0.45661953 -0.03104173  0.74640964\n",
      "  0.37032675 -0.45300674  0.14048464  0.29848582 -0.66721124 -0.02924557\n",
      "  0.06185449  0.01144127 -0.2198804   0.43754997  0.51305779  0.535481\n",
      " -0.05857565 -0.55156766 -0.19699542  0.32552092  0.49812863  1.05022886\n",
      " -0.46880077  0.13185008  0.45662794  0.01598062  0.22679811  0.54983921\n",
      " -0.51309875 -0.25350072  0.1427328   0.04749266  0.11206363 -0.06661182\n",
      "  0.34600351 -0.37654656 -0.01306791  0.29597598 -0.46505005  0.03232198\n",
      "  0.26106422  0.75008766 -0.62458911 -0.41358922 -0.1428284   0.49983785\n",
      " -0.08443853 -0.67937754]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_sent_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(len(tfidf_sent_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train,CV,Test - AvgTF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data set into train and test\n",
    "X_1_avg_tf, X_test_avg_tf, y_1_avg_tf, y_test_avg_tf = cross_validation.train_test_split(tfidf_sent_vectors, sample_labels, test_size=0.3, random_state=0)\n",
    "\n",
    "# split the train data set into cross validation train and cross validation test\n",
    "X_tr_avg_tf, X_cv_avg_tf, y_tr_avg_tf, y_cv_avg_tf = cross_validation.train_test_split(X_1_avg_tf, y_1_avg_tf, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "X_tr_avg_tf = pd.DataFrame(data=X_tr_avg_tf)\n",
    "X_tr_avg_tf = X_tr_avg_tf.fillna(X_tr_avg_tf.mean())\n",
    "print(X_tr_avg_tf.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85916313381243659, 0.87159168044521618, 0.87259169298505967, 0.87340803201641626, 0.87332638270022933, 0.87330595787893794, 0.87328554554989135]\n"
     ]
    }
   ],
   "source": [
    "C_Val = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "cv_scores_avg_tf = []\n",
    "for val in C_Val:\n",
    "    Log_reg_avg_tf = LogisticRegression(C=val)\n",
    "    scores_avg_tf = cross_val_score(Log_reg_avg_tf, X_tr_avg_tf, y_tr_avg_tf, cv=10, scoring='accuracy')\n",
    "    cv_scores_avg_tf.append(scores_avg_tf.mean())\n",
    "print(cv_scores_avg_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of alpha is 1.\n"
     ]
    }
   ],
   "source": [
    "# changing to misclassification error\n",
    "MSE_avg_tf = [1 - x for x in cv_scores_avg_tf]\n",
    "\n",
    "# determining best k\n",
    "optimal_aplha_avg_tf = C_Val[MSE_avg_tf.index(min(MSE_avg_tf))]\n",
    "print('\\nThe optimal number of alpha is %d.' % optimal_aplha_avg_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAETCAYAAABEEROeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VNX5x/FPFhYDQQLEDau4wGNVwF1wxVZ+1bburVar\nqIiAihtaEUXFulAX3EAQsAr6019rVRStS90XFK0KsgiPUvetgiYBEsg6vz/uTZiEycyEZIDMfN+v\nF6/ce+45954zCXlyt/NkRSIRRERE0k32xu6AiIhIKijAiYhIWlKAExGRtKQAJyIiaUkBTkRE0pIC\nnIiIpKXcjd0BkdbOzHoAnwFvuPshDbbdD5wBFAI7A+OArgR/XH4FXOrui8K6EWAhUN3gEMe6++ep\nG4FIelKAE2kZa4BeZra9u38BYGYdgIPC7TnA08D/uPsH4fZTgWfNbAd3rw1qh7n78g3cd5G0pEuU\nIi2jGvg78MeosuOBJ8PlGqAz0DFq+0PACILgJyItTGdwIi3nAeBB4MZw/XTgIuASIAJcBjxnZt8D\ns4FXgL+5e0XUPl4xs+hLlJ+5+3Ep77lIGsrSVF0izRPeg1vo7h3NbCFBYPsBeNTd9w/vrRW6+3Iz\nywcOBQ4Bjgl3sZ+7l0TX2wjDEEk7ukQp0rIeBE4FTguXa+1mZn9y95Xu/rS7XwbsRnDpcuBG6KdI\n2lOAE2lZ/wv8HjgJeDiqfDUwxswOiirbGugALNhw3RPJHLoHJ9KC3P0bM1sMlLj7T1GbPgWOBW40\ns20JnrosAYa6u0fVa3gPDuAKd38mpR0XSUO6ByciImlJlyhFRCQtKcCJiEhaUoATEZG0pAAnIiJp\nKS2foly2bGWznpwpKMijqKispbrTKmTamDNtvKAxZ4rmjLmwMD+rhbuzUekMLobc3MybGjDTxpxp\n4wWNOVNk4pgbowDXiJKSYm6++QYA3nzzdYYMGcSwYWcya9bMdeoWFxdz8cXnce65Q7j66tGsWbMm\nYbtFixYyYsTQhP24776pnH32IIYPH8xHHy2MWae6upoxYy5jzpy36pWvWbOGM844ZZ3yRx55mMmT\nJ9Stjx9/E8uXa3YoEUkvCnCNmDZtMscffyJVVVVMmHAbt902kYkTpzJr1kx++unHenWnT5/GwIFH\nMGnSvfTsaTz55GNx2z300Axuuuk6KioqYh26jvsS5s37gKlTZzB27I3cdtvN69T55puvGTHibBYv\n/midbbfddhNZURccysvXcO21Y3j88X/Uq/f735/E+PHjk/1oRERaBQW4GFatWsXixR+x8849+fzz\nz+je/Wd06tSJNm3a0KdPX+bNm1uv/vz589h///4A9Ot3AO+9927cdt27b8sNN9ySsB/z589j3337\nkZWVxVZbbUV1dRVFRUX16pSVlTFq1FXstdc+9coffvhBdt+9Dzvv3KuurLy8giOP/C2DBg2uV3e7\n7Xrw6aefUlJSnPyHJCKyiVOAi2HevHlst932AJSWltKx49oUXnl5HSgtXVWvfnSdvLw8Vq1aFbfd\ngAG/JDc38fM9paWrEh67Z89e9OixQ72y9957l6+//pKjj66fZaVTp07st1+/mMfacccdWbDgw4R9\nEhFpLdLyKcrmKioqokuXLgB06NCBsrLSum1lZfUD19o6ZbRr156ysjLy8/OTapdIhw4dY+wjP2G7\np59+kv/+9ztGjBjKl19+wccfL6Fr16707GmNtiksLKSkpKRJ/RMR2ZTpDC6Grl27snLlSgB69NiB\nr7/+ihUrSqisrGTevLnsvnufevV79+7L22/PBmDOnLfo02ePpNol0rt3X959dw41NTV8//331NRE\n6Ny5c8J2Y8fewOTJ9zFx4lT2378/55xzQdzgBlBSUkJBQZcm9U9EZFOmABdD3759Wbr0EwByc3MZ\nMeJiRo48n2HDzuQ3vzmawsItWLGihCuu+BMAp59+Fi+++C/OOWcwixbN54QTTmq0XWOeeeYpnnnm\nqXplu+zyc/r02YNhw85kzJjLGDlyFADvv/9v7r9/WouOefHixfTtu0eL7lNEZGNKy2wC6/uid1V1\nDY+8spRjBvRk0u3jOOaY4+nVa5eW7l5MS5d+wpIlH/Hb3x6TuHIL++yzT3nyyUe46KLLN/ixN5bC\nwnyWLVu5sbuxQWnMmaE5Y9aL3mnsqx9W8eJ7X/Pq+18xZMhwZs58dIMdu1OnTvzmN0dvsONFe+yx\nv3PhhRdulGOLiKSKAlwMNREoKOjCqFFjNtgxt9hiS7KyNs4fT5deOpottmj88qmISGukACciImlJ\nAU5ERNKSApyIiKQlBTgREUlLCnAiIpKWFOBERCQtKcCJiEhaStlky2aWDUwC+gLlwBB3X9qgTh7w\nAnCWuy+JKt8CeB8Y6O5LzGxnYDoQARYC57l7Tar6LiIirV8qz+COBdq7e3/gcqBeRk0z2wd4Hdip\nQXkbYAqwOqr4NmCMux8MZAEbfj4rERFpVVIZ4A4CngNw9znAPg22twOOA5Y0KL8VuAf4Nqpsb+C1\ncPlZ4PCW7qyIiKSXVOaD6wREJxirNrNcd68CcPfZAGZr07iY2RnAMnd/3sxGR7XNcvfaCZRXApvH\nO3BBQR65uTlN7nDR6qq65cLCxHnX0k2mjTnTxgsac6bIxDHHksoAtwKI/pSza4NbHIOBiJkdDuwB\nPGBmRwPR99vygeJ4OykqKluP7kJx8dp2moE8vWXaeEFjzhTNzCbQwr3ZuFJ5iXI28GsAM+sHLEjU\nwN0PcfdD3X0AMA8Y5O7fA3PNbEBY7UjgjZT0WERE0kYqz+BmAgPN7C2CB0PONLNTgI7uPrWJ+7oE\nmGZmbYHFwIbLYyMiIq1SygJc+Bj/8AbFDR8oITxbi9V+QNTyx8ChLdg9ERFJc3rRW0RE0pICnIiI\npCUFOBERSUsKcCIikpYU4EREJC0pwImISFpSgBMRkbSkACciImlJAU5ERNKSApyIiKQlBTgREUlL\nCnAiIpKWFOBERCQtKcCJiEhaUoATEZG0pAAnIiJpSQFORETSkgKciIikJQU4ERFJSwpwIiKSlnJT\ntWMzywYmAX2BcmCIuy9tUCcPeAE4y92XmFkOMA0wIAIMd/eFZrYHcA9QBXwc7qsmVX0XEZHWL5Vn\ncMcC7d29P3A5MD56o5ntA7wO7BRVfBSAux8IjAFuCMuvAf7s7gcB7YDfpLDfIiKSBlIZ4A4CngNw\n9znAPg22twOOA5bUFrj7E8DQcHV7oDhcngt0MbMsIB+oTF23RUQkHaTsEiXQCSiJWq82s1x3rwJw\n99kAZlavkbtXmdkMguD3u7D4E+BugrO6EuDVeAcuKMgjNzenyR0uWl1Vt1xYmN/k9q1dpo0508YL\nGnOmyMQxx5LKALeC4GyrVnZtcEvE3U83s1HAO2a2K3AncLC7LzKz8wgud57XWPuiorL16nBx8dp2\ny5atXK99tFaFhfkZNeZMGy9ozJmiOWNOt8CYykuUs4FfA5hZP2BBogZmdpqZjQ5Xy4Ca8N9PBAET\n4FugoMV7KyIiaSWVZ3AzgYFm9haQBZxpZqcAHd19aiNtHgfuN7PXgTbARe6+2syGAH8zsyqgAjg7\nhf0WEZE0kLIAFz7GP7xB8ZIY9QZELZcCJ8ao8yZwYAt3UURE0phe9BYRkbSkACciImkpYYAzsz4b\noiMiIiItKZkzuL+nvBciIiItLJmHTD4ys6uBd4DVtYXu/nrKeiUiItJMyQS4LsBh4b9aEeAXKemR\niIhIC0gY4Nz9MAAzywdy3L04QRMREZGNLmGAM7Mdgb8RzPqfZWZfACe6+yep7pyIiMj6SuYhkynA\nze7e1d27AOMIcraJiIhsspIJcN3c/dHaFXd/hOC+nIiIyCYrmQBXbmZ71a6Y2d4EEyGLiIhsspJ5\nivJC4DEz+4lg0uQuwEkp7ZWIiEgzJRPgugG9wn/ZgLt7RUp7JSIi0kzJBLib3f2fwKJUd0ZERKSl\nJBPg/mNm97HuTCYPpKxXIiIizZRMgPuR4N5bv6iyCKAAJyIim6xkAtw37j4m5T0RERFpQcm8JnCU\nmWWlvCciIiItKNlLlEvM7APq34MbnLJeiYiINFMyAW5GynshIiLSwhoNcGbW3d2/cfd1ApyZJUyV\nY2bZwCSgL1AODHH3pQ3q5AEvAGe5+xIzyyGY59IIHmQZ7u4LzWyLsLwAyAEGuft/kh2kiIhknnj3\n4J6qXTCzxxpsuzWJfR8LtHf3/sDlwPjojWa2D/A6QZaCWkcBuPuBwBjghrD8ZuAhdz8kLN8lieOL\niEgGi3eJMvrBkh3jbGvMQcBzAO4+Jwxo0doBxwEP1ha4+xNm9nS4uj1Qm3vuQGC+mb0IfE4wfVij\nCgryyM3NSaKL9RWtrqpbLizMb3L71i7Txpxp4wWNOVNk4phjiRfgIo0sx1qPpRNQErVebWa57l4F\n4O6zAcysXiN3rzKzGQTB73dhcQ+gyN0PN7OrgVHA1Y0duKho/eaCLi5e227ZspXrtY/WqrAwP6PG\nnGnjBY05UzRnzOkWGJN5TWB9rQCiP63s2uCWiLufTjD35TQz60DwJOescPNTQMOzQRERkXrincFt\nHZ4tNVzOArZKYt+zCe6pPWJm/YAFiRqY2WnAtu4+jiAlT034703g1wSXMw9B82KKiEgC8c7g7iEI\nZlkNliHI8p3ITGCNmb0F3A5cbGanmNnQOG0eB/Y0s9eB54GL3H01cAkwKNzXEcCNSRxfREQyWKNn\ncO5+bXN27O41wPAGxUti1BsQtVwKnBijzhfAwOb0R0REMksq78GJiIhsNApwIiKSlhTgREQkLSWc\ni9LMfkUwo0gBax80ibh7w5e/RURENhnJTLY8ARgJLCS5F7xFREQ2umQC3HJ3fzpxNRERkU1HMgHu\nDTO7jWBeyTW1he7+esp6JSIi0kzJBLj9wq97RpVFgIQpc0RERDaWhAHO3Q8DMLN8IMfdixM0ERER\n2eiSeYpyR+BvBHnbsszsC+BEd/8k1Z0TERFZX8m8BzcFuNndu7p7F2AcQXZtERGRTVYyAa6buz9a\nu+LujwBdUtclERGR5ksmwJWb2V61K2a2N0EqGxERkU1WMk9RXgQ8ZmY/Ecxi0gX4Q0p7JSIi0kzJ\nPEU5x8x6EWTYzg6KvCLlPRMREWmGRgOcmY1197Fmdj8NpugyM9x9cMp7JyIisp7incG9H359NcY2\nzUkpIiKbtHgZvZ8KF7dx93HR28zsxpT2SkREpJniXaL8C7AFcLSZ9WzQph9wRYr7JiIist7iXaJ8\nDNgV+CXwWlR5FXBdoh2bWTYwCegLlAND3H1pgzp5wAvAWe6+xMxyCF4iN4LLoMPdfWFU/VOA8929\nfxJjExGRDBbvEuW/gX+b2RPuXlJbbmZZwA5J7PtYoL279zezfsB44Jio/ewD3ANsG9XmqPDYB5rZ\nAIJEq8eE9fcEziJ4VUFERCSuZF70Ps3MVphZtZlVE5zBvZBEu4MIUuzg7nOAfRpsbwccByypLXD3\nJ4Ch4er2QDGAmXUFbiR4J09ERCShZF70voTgMuMNBPfdBgADk2jXCSiJWq82s1x3rwJw99kQvHIQ\nzd2rzGwGQfD7XXjZ8q8EWcVXJ3FcCgryyM3NSaZqPUWrq+qWCwvzm9y+tcu0MWfaeEFjzhSZOOZY\nkglwP7j7Z2Y2H+jt7tPNbEQS7VYA0Z9ydm1wS8TdTzezUcA7wCCgJzAZaA/samZ3uHujZ3NFRes3\nk1hx8dp2y5atXK99tFaFhfkZNeZMGy9ozJmiOWNOt8CYzCXKUjM7DJgPHGVmWwEFSbSbDfwaILwH\ntyBRAzM7zcxGh6tlQA3wrrvv5u4DCKYI+yhecBMREYHkAtwFBA9/PAd0JbhnNiGJdjOBNWb2FnA7\ncLGZnWJmQ+O0eRzY08xeB54HLnL3pC5LioiIREtmLsqFZvagu9eY2WBgH3d/KYl2NcDwBsVLYtQb\nELVcCpwYZ5+fE7yDJyIiElfCM7jwhe+bwtU84CozG5vKTomIiDRXMpcofwscCeDu3wGHAyekslMi\nIiLNlUyAywU2i1pviyZbFhGRTVwyrwlMAd43s9rJl48EJqauSyIiIs2X8AzO3W8HTgW+A74ETnX3\nyanumIiISHM0GuDM7Lfh10HAz4FlBFNn9Q7LRERENlnxLlHuAzwNHBZjWwR4ICU9EhERaQHxAtwh\n4df/uPv1G6IzIiIiLSVegOthZtcDg8PcbvW4+59T1y0REZHmifeQyQkEiUqzGvknIiKyyYqX8HQu\nMNfM3nP3Zzdgn0RERJqt0QBnZlPdfShwmZn9qeF2d/9FSnsmIiLSDPHuwU0Jv47dAP0QERFpUY3e\ng3P398PFt4Eid38N6E4wN+XHG6BvIiIi6y2ZuSj/F/idme0HXEuQqXtGSnslIiLSTMkEuB3c/Wrg\nd8C97n4dyWX0FhER2WiSyiZgZt2AY4F/mtlWBHnhRERENlnJBLhbgHeAf7r7QuB1QC95i4jIJi1h\nuhx3fxh4GMDMOgHHufuiVHdMRESkORIGODM7CzgQGAXMBVaa2WPuPibVnRMREVlfySQ8PRcYSJAT\n7kngQmAOEDfAhfNXTgL6Ekz5NcTdlzaokwe8AJzl7kvMLAeYBhhBxoLh7r7QzPYAJgDV4b4Guft/\nkx6liIhknGTuweHuPwG/JrgPVwVslkSzY4H27t4fuBwYH73RzPYhuJ+3U1TxUeHxDiQIoDeE5XcC\n57v7AOBxgrNJERGRRiUT4BaZ2dPAjsCLZvYI8F4S7Q4CngNw9zkE+eWitQOOA5bUFrj7E8DQcHV7\nggSrAH9w93nhci6wJonji4hIBkvmEuVg4ABgobtXmNmDwDNJtOsElEStV5tZbngGiLvPBjCzeo3c\nvcrMZhAEv9+FZd+FdQ8ARrA2V11MBQV55ObmJNHF+opWV9UtFxbmN7l9a5dpY8608YLGnCkyccyx\nJBPgugB7A4eaWRaQA/weGJSg3Qog+lPOrg1uibj76WY2CnjHzHZ191IzOwm4EviNuy+L176oqCyZ\nw6yjuHhtu2XLVq7XPlqrwsL8jBpzpo0XNOZM0Zwxp1tgTOYS5ePAHgQPmXQAjgZqkmg3m+C+HWbW\nD1iQqIGZnWZmo8PVsvA4NWZ2KsGZ2wB3/zSJY4uISIZLJsB1c/fTgacIgt0AYLck2s0E1pjZW8Dt\nwMVmdoqZDY3T5nFgTzN7HXgeuAioAO4iOBt83MxeNbNrkzi+iIhksGQuURaFXx3o6+7vmFmbRI3c\nvQYY3qB4SYx6A6KWS4ETY+yuSxL9FBERqZNMgHvZzP4BXAr8y8z2Qk8xiojIJi7hJUp3vxK43N2/\nAE4mOJM7LtUdExERaY5Gz+DMbFCD9QPDxR8JZjZ5IIX9EhERaZZ4lygPi7MtggKciIhswhoNcO5+\nZu2yme3p7nPNbHNgb3d/eYP0TkREZD0lvAdnZuOAm8LVPOBqMxubyk6JiIg0VzLvwR0FHAl1U2Yd\nDpyQyk6JiIg0VzIBLpf62QPaEtyDExER2WQl8x7cFOB9M3sKyAKOACamtFciIiLNlMx7cLcTzEP5\nHfAF8Ed3n5zqjomIiDRHMg+ZdAE2d/fxQEfgSjPbNeU9ExERaYZk7sH9H7CLmf2S4OGSWcA9Ke2V\niIhIMyUT4ArcfSJwLDDD3R8keF1ARERkk5XMQybZZrY3QYA71Mz2SLKdiIjIRpPMGdwo4BZgfJhs\n9B5gZEp7JSIi0kwJz8Tc/SXgpaj1fintkYiISAuIl03gA3ffy8xqqP9idxYQcfeclPdORERkPcWb\nbHmv8GsylzFFREQ2KUnng2vI3ZUuR0RENlnx7sFNB34AXgQqCC5N1lI+OBER2aTFC3B7AScRZO/+\nEPgb8KK71ySzYzPLBiYBfYFyYIi7L21QJw94ATjL3ZeYWQ4wDTCCIDrc3Rea2c4EATcCLATOS7Yf\nIiKSmRq9v+bu89x9tLvvA0wmCHTvmtk9ZjYgiX0fC7R39/7A5cD46I1mtg/wOrBTVPFR4bEPBMYA\nN4TltwFj3P1ggjPJY5I4voiIZLCkHiBx9/fc/U/AxUBv4Okkmh0EPBe2nwPs02B7O+A4YEnUcZ4A\nhoar2wPF4fLewGvh8rMEOelEREQaFfc9ODPLAg4Bfk+Q9HQeMAF4Kol9dwJKotarzSzX3asA3H12\neIx6jdy9ysxmEAS/34XFWe5e+6rCSmDzeAcuKMgjN7fpbzEUra6qWy4szG9y+9Yu08acaeMFjTlT\nZOKYY4n3FOVkgtxvc4FHgFHuXtqEfa8Aoj/l7Nrgloi7n25mo4B3wswF0ffb8ll7ZhdTUVFZE7q5\nVnHx2nbLlq1cr320VoWF+Rk15kwbL2jMmaI5Y063wBjvEuUwgvQ4ewLjgAVm9mntvyT2PRv4NYCZ\n9QMWJGpgZqeZ2ehwtYwgsNUAc6Pu+x0JvJHE8UVEJIPFu0S5QzP3PRMYaGZvETwYcqaZnQJ0dPep\njbR5HLjfzF4H2gAXuftqM7sEmGZmbYHFwKPN7JuIiKS5eDOZfNGcHYeP8Q9vULwkRr0BUculwIkx\n6nwMHNqc/oiISGbRNFwiIpKWFOBERCQtKcCJiEhaUoATEZG0pAAnIiJpSQFORETSkgKciIikJQU4\nERFJSwpwIiKSlhTgREQkLSnAiYhIWlKAExGRtKQAJyIiaUkBTkRE0pICnIiIpCUFOBERSUsKcDFE\nIhFKSoq5+eYbAHjzzdcZMmQQw4adyaxZM9epX1xczMUXn8e55w7h6qtHs2bNmrpta9as4ZxzBvPF\nF5/HPebChQs4++zTOeecwdx3X2MJz+G1115h7Ngr69bfe+9dhg07k/POO5sxYy6rO/aECbdx9tmD\nGDr0DObPnwfA22/P5umnn0j6cxARac0U4Boxbdpkjj/+RKqqqpgw4TZuu20iEydOZdasmfz004/1\n6k6fPo2BA49g0qR76dnTePLJxwBYsuQjzjvvbL755puEx7v11nGMHXsDkyb9lY8+WsjHH6+T/Jw7\n7riVKVMmEonU1JWNH/8Xxo27lbvvnsa2227HU089wSeffMyCBfOZOnUGV131Z+6441YA+vc/kFde\neZnS0lXN+WhERFoFBbgYyteUsXjxR+y8c08+//wzunf/GZ06daJNmzb06dOXefPm1qs/f/489t+/\nPwD9+h3Ae++9C0BFRQU33ngL2223fdzjlZauorKygu7dtyUrK4v99utft49ovXv34dJLR9crmzBh\nKl26dAWgurqatm3bUli4Be3bt6eiooLS0lJyc3Pr6vfvfwDPPPN00z8UEZFWRgEuSlZW8PXbLz6u\nC0qlpaV07Nixrk5eXod1zoCi6+Tl5bFqVbC9T5892HLLrRIet7S0lLy8DlHHWLuPaL/85f+sU9at\nWzcAXnvtZT744D2OOOI35OTkkJWVzR//+DsuuuhcTj751Lr6O+3Uk7lz30/YJxGR1i43cZX1Y2bZ\nwCSgL1AODHH3pQ3q5AEvAGe5+xIzawPcB/QA2gHXu/ssM9sDuAeoAj4O91VDipSVrqRLly4AdOjQ\ngbKy0rXbyuoHvLV1ymjXrj1lZWXk5+c36XgdOnRg9eqyqGOU0bFj8vv4+98f4tVXX2L8+Am0a9eO\nWbNm0rVrV267bQJlZWWce+5Z7LZbb7bYYku6du3GihUlTeqfiEhrlMozuGOB9u7eH7gcGB+90cz2\nAV4HdooqPhX40d0PBo4AJobl1wB/dveDCALfb1LR4SyCU7i8jp1YuXIlAD167MDXX3/FihUlVFZW\nMm/eXHbfvU+9dr179+Xtt2cDMGfOW/Tps0eTjtuhQ0dyc9vwzTdfE4lEePfdt+nbd8+k2s6Y8Vc+\n/HAed9wxic6dOwOQn5/PZpttRk5ODnl5ebRp05Y1a1YDsHLlSjp3LmhS/0REWqOUncEBBwHPAbj7\nnDCgRWsHHAc8GFX2D+DRcDmL4IwNYC7QxcyygHygMt6BCwryyM3NaXKHS8qrAdh6u5689NZjFBYG\nZ1FXXnkFl112IZFIhD/84UR23XUniouLGTNmDBMnTmTkyAsZNWoUzz47i4KCAsaPH09eXl7dftu2\nzaWgII/CwnyWLVvGjTfeyO23317v2DfccB033ngN1dXVHHTQQQwYENzTGzx4MPfccw9t27YFoHPn\nPNq1a0NhYT7Lly9n+vR72XXXXRk9eiQARx55JKecchLXXvsR559/NtXV1Rx//LHsvXdvAL788hMG\nDDi4bmzRYpWls0wbL2jMmSITxxxLViQSScmOzexe4DF3fzZc/xLY0d2rGtR7FRju7kuiyvKBWcA0\nd3/YzE4G7gZ+AEqAQ919DY1Ytmzleg3qi+9Xcu30f3P0ITvyyeyHOeaY4+nVa5f12VWjqqqqmDx5\nAueff3GL7jdZI0eez3XXjaNDh/qXWYPgu3Kj9GljyLTxgsacKZoz5sLC/KwW7s5GlcpLlCsIzrbq\njtUwuMViZj8DXgEedPeHw+I7gYPdfRfgARpc7mxxERgyZDgzZz6auO56OOWU01Ky30TeeutNBgz4\nxTrBTUQkHaXyEuVs4CjgETPrByxI1MDMtgT+BYxw95eiNv1EEDABvgUObOG+AmufogQoKOjCqFFj\nWvwYubm5dO3arcX3m4wDDjhooxxXRGRjSGWAmwkMNLO3CO6nnWlmpwAd3b2xqTquAAqAq8zsqrDs\nSGAI8DczqwIqgLNT2G9Sc9FWREQ2pJQFuPAx/uENiteZnsPdB0QtXwhcGGN3b5KiszYREUlPetE7\nhlQ9eCMiIhuOAlyUrKy0eoBIRCSjpfIeXKtTG94iEfjqqy+4/PJLeOihR3n++We5667xVFRUcMop\np3Hyyadx8cXncvnlV7P99j2oqalh/Pi/8M47b1NeXk6XLl3Iy8tj3337MXjw0HrHKC9fw+DBp/Ld\nd99SU1PDTTfdzv77B3NPTps2GYCffvqR22+fxKBBJ7L11t1ZvvwHttlmWz75xGnXrj2VlRXk5eWx\n8869+OKLz6moqKCmpobVq8vIzc3lyCN/y7x5HzBx4tSYD7QUFxdz7bVXUl5eTrduhVxxxTXUf+A1\n8PXXX3FcHJL7AAAT+UlEQVTFFZfywAN/B+D7779n3Lg/U10dPAx72WVX0KFDR6655oq6NkuXfszw\n4SM45JDDmD79XkaOHNUC3xkRaYqSkmKmTLmbyy4LMo+sWbMm5u+spUs/oU2bNlx++VVsu+3PMLOd\ngekEjyIsBM5z9xozOxsYRvBu8vXu3uiEtmZ2FHB1WPc+d5/WSL2LgK3c/fJw/WTgorDdAuBcYBBw\nRtikPbAHsBXwB+CTBg8jrkNncFFycoIQV1Vdw+jRlzJkyHCqqqq45ZYb6dRpc9q3b8+zzz7N8OFn\n1ssQ8PLLL/Duu3PIzc2lqqqSgoIujWYFmDJlEsuWLWPLLbdihx124vrrrwHWZgXo2bMX3bptwamn\n/o6KigqqqirrglrnzgVcffWfOeCAgygtLeXEE09mt9125/nnX+XnP9+VNm3acPfd08jOzqZnT+Oq\nqy6POc7Gsh9Ee+65f3LNNVdQXFxcV3bvvZM54YQTmThxKqeddib33HM3Xbt2Y+LEqUycOJXhw0fQ\nq9cuHHXUcXTp0pW8vA6a91JkI6jNhgKxs5q88carVFRUMGXK/Qwffj4TJ9ZNPHEbMCacTSoLOMbM\ntgIuIHgO4lfAODNrF+u44XSLtwP/AxwKDA2fjo+us5mZPQScF10GXA8c5u4HApsDv3X36e4+IHxW\n433gAncvBu4FrjSzuDN6KMBFyckJPo7in5bx3Xffcdhhh7N48SIgwh133M322/fgZz/bjmOOOaFe\nhoB58+Zy+OH/w0kn/ZGsrGw+//yzRrMCvP/+v9ltt93505+uYJtttqG0dBVFRUVMmDCVdu3asXjx\nR7Rv35YTTzyFtm3bcuqpZ7D11ttQXl7O1KnTmT9/Hrvt1ofs7Gy++uorlixZDMCHH85lwIBfsttu\nvenX7wA22yyPTz5xSkqKaaix7AfR8vM7MXFi/YddR4y4uO5Vg9rMBbUikQi3334Ll156OTk5wc/c\nwIFH8I9//K2p3wYRaYZVq1bVZUOB2FlNon8H7L5777rfI8DewGvh8rPA4cB+wGx3L3f3EmApUH++\nwrV+Dix19yJ3ryB4QPCQBnXaAzOAG6LKyoED3L12Ut5coG4yj3AmrN1qn8AP36meS4JpGxXgorQJ\nA9ziuW9QUBDM17ho0UI237xzXVaArbfuXi/9DEBVVSV9+uxJeXk5bdq0ITs7m6qqqphZAVavLmO3\n3YJps3JycolEIpSWrqJbt24sWrSQ9u3bsWLFSs46axjZ2Tl07lzADz/8l6OOOpZttunO8uXLmTHj\nr+y3X38WLVpAdnY2ixYtpLq6mksuCc7Y8vI6UFlZAWTx7rvvrDPOxrIfRDvwwIPZbLPN6pV17tyZ\n3Nxcvvzyc+6++w4GD177tsbs2a+zww47st12PerKevTYoS7ZqohsGPPmzasXzGJlNSktLa034UPt\n7ywgy91rn7JbSXAm1YlgBikalMeSsG4Y/P7VoKzG3f8LYGbnAx0JJuKvdQVwbYNjzQcGNNKPYFzx\nNmaa2kuUq1b8SKdOnQCorKys9/DJmjWr42QTaEdlZSWRSITc3NyYWQE22yyPFSuCd9arq6vIysqq\nq/Pcc//k66+/rssKALXZxUvo3/9A5s+fx6uvvkSvXrtw/vkXs2JFCZFIhIcffoA2bdrU9as240GH\nDh344Yfv1xlnbX+Duk3LfvDBB+8xevSlXHXVn+sFs+eff5ajjz6uweeZQ25uLjU1KUv8ICINFBUV\n1WVDaUz07wCg7ncWEP2fNR8oZt1ZqWrLY2lK3XrMLNvMbgUGAifUBloz6wyYu7/SoMl3QNd4+1SA\ni5KbHXwcm3XsUvfN79mzFytWrKgLJkuWfBQzm8CcObNp164dkUgN3btv22hWgL322oe3336Tmpoa\nvv32W9q334zOnTszY8Zf+e67b9l33/3qsgIAfP/9d7Rv355vvvmGCy88l8MOO5zu3buzcuVKsrKy\n2XHHnfnww7lsv/0OfPDBe0CQ0aBv3z0pL1/DNttsu8441zf7wQcfvMedd97K+PET2GWXXettW7Jk\nMb17961XFolEyMnJITtbP2YiG0rXrl3rsqE0pvZ3FsDChQvYccedazfNNbMB4fKRwBvAu8DBZtbe\nzDYnuAy5sJFdLwZ6mlkXM2tLcHny7SS7PoXg8uWxUZcqCfcR62GSAoL5iRul3zxRcsMzuO1+fgDL\nlgWfW58+e1BQUMDIkefz8cdLOPTQX1BYuAVr1qxhxIjgCclDDjmMtm3bMmPGX8nOzmHlypWcffbp\nfP7557z77lsAXHzxeVRWVjJs2Hm0bduOUaMu5tNPlzJ69FX89NOP3HvvPXz++We89torjBgxtG4e\nzOXLl9GuXTsmT76LqqpK3nrrTV544bnwQZevuOCCkZSWlnLWWUO5776pDBt2JpWVley9935UVVXz\n4ovP8eOPy+uN8/TTz+LFF//FOecMZtGi+ZxwwkkATJp0Jx991NjPLdx553gqKyu5/vprGDFiKDff\nHFxCLyoqokOHDuu8ZvGf/yxl9917N/fbIiJN0LdvX5Yu/SRundrfWcOHD2bChNu44IKRtZsuAa41\ns7eBtsCj7v49cBdBsHsZuNLd15jZHmZ2R/R+3b0SGAk8TxDY7nP3b8KA93hj/TGzvYCzgN7Ay2b2\nqpnVXhIy4NMYzfYnduCrk7JsAhvT+mYTqKmJMOTmV+izczfee+I6Tj/9LAYOPIJbbrlxncwCyWQF\nmDx5Ah07duS0085Mug+xjhVLY1kBak2bNpkPP5xL7959GTRo8Dr30xpKxazrkybdyYEHHkrfvk3L\nj7chaJb5zJCpY77sstHrlQ2lKdkEzKwDcIW7X9nUPjaXmeUS3KM73N2rG6unM7go2dlZZGVBZVUN\n1133F+6/P3h9o7HMAomyAhxyyGGceuoZTepDMlkMEmUFKC9fw0sv/Yurr76eY445IWFwS4Uff1xO\naWnpJhncRNJdKrOhRMkFbkr1QRoxFBgXL7iBzuDWMfzWV9l+606M/uNerCiroGxNFTU1ESKRCDWR\n4CwvQoSaGqiJhOU1wbagTrAt5nIkQiTcR91yJEIkqn2tdQYQibsavJ3eyLZE3+IIETp2aMeq0vKE\nx4n389JwU7w+rrM9lcdtUBKJQF5eW8rKKpLYV+M7T/w9Wve4jUnpccOvm7Vvw+rVlTG3NdaRSOOb\n1mkd9/vQhPE1+bhxNrdtl0t5+dosXYl+38UfQ/LHbbja1OPW35bguA3077MN+1thglqxpVs+OM1k\n0kBOTjY/lqzm9kc+ZOGnPyqzgIi0KrltctY7wKUbBbgG2uRk8dOKcn5aUc5O3TvRvVtHsrMgKzuL\n7KzgEmZ2Vlbd5czsrKjy7PrLWWSFZcE8l/WWs7LIzo5ezqLhn07rTo2ZFXd7VqMrsM7eG6x23nwz\nSkpWb/DjZjW+aZ0DJf58orfF/0O0oCCP4uKyJvexYUHDtommM82K0zZe3XW3xf9sYo2hoEsHin4q\nbdHPNZnjNrbjdY4bZ19N/5yDCl27duDHH0vjtm3Sz12CtvF+7hIetwljXHdfawu6b7M5y5ev+25r\nJlKAa+CoA3eguKySfXt1Y7stk38/rLXLtJvxwXjbJq6YRgoL88nLSasrUAl13XwzaiqqEldMI5o0\nfi0FuAZ+ufe2GffLXkQkHekpShERSUsKcCIikpYU4EREJC2l7B6cmWUDk4C+BKkQhrj70gZ18gje\nRj/L3ZeEuYTuA3oA7QgS680ysy2AaQRzj+UAg9z9P6nqu4iItH6pPIM7Fmjv7v2By4Hx0RvD/D6v\nAztFFZ8K/Bgm2zsCmBiW3ww85O6HAGOAps0/IyIiGSeVAe4g4DkAd58D7NNgezvgOCA65fU/gKvC\n5SyC1OUQZJLd1sxeBP4IvJqaLouISLpI5WsCDRPfVZtZbpiJFXefDWBmdRXcfVVYlg88SnC2BsEl\nyyJ3P9zMrgZGAVc3duCCgjxyc+NmMk+osDBz3oGrlWljzrTxgsacKTJxzLGkMsA1THyXXRvc4jGz\nnwEzgUnu/nBY/CMwK1x+ivqpztdRVFQWb3NCmfgeXKaNOdPGCxpzpmjOmNMtMKYywM0GjgIeMbN+\nwIJEDcxsS+BfwAh3j87z8ybwa+BBguR3i+LtpyUmDE23b3QyMm3MmTZe0JgzRSaOOZaUZROIeoqy\nD8H9tDOBvYCO7j41qt6rwPDwKco7gZOof1/uSGAL4F6gA8Flz1PcvSglHRcRkbSQlulyRERE9KK3\niIikJQU4ERFJSwpwIiKSlhTgREQkLSnAiYhIWlLC01Ayk0O3VrEmsQY+AqYDEWAhcJ6715jZ2cAw\ngmnSrnf3pzdGn1tKOFH3+8BAgjFNJ43HbGajgaOBtgQ/z6+RxmMOf7ZnEPxsVwNnk8bfZzPbH7jJ\n3QeY2c4kOU4z2wz4X4JXrlYCp7v7so0yiA1IZ3BrxZ0cupWLNYn1bcCYsCwLOMbMtgIuIJj781fA\nODNrt5H63GzhL78pwOqwKK3HbGYDgAMIxnIo8DPSfMwEE0DkuvsBwJ8JZjlKyzGb2WUE7wO3D4ua\nMs5zgAVh3QdYOw1iWlOAWyvR5NCtWaxJrPcm+Ose4FngcGA/YLa7l7t7CbCU4EX91upW4B7g23A9\n3cf8K4IZg2YSTGn3NOk/5o+B3PAKTCegkvQd83+A46PWmzLOut9vUXXTngLcWjEnh95YnWlJ7r7K\n3Vc2mMQ6y91r3/JfCWzOup9BbXmrY2ZnAMvc/fmo4rQeM9CN4A+z3wPDgYcI5oBN5zGvIrg8uYQg\nZ+RdpOn32d0fIwjgtZoyzujyVjf29aUAt9Z6TQ7dWoSTWL8CPBhOYl0TtTkfKGbdz6C2vDUaDAwM\np4Lbg+CyzBZR29NxzD8Cz7t7hbs7sIb6v8jSccwXE4y5F8H98xkE9x9rpeOYazXl/3B0eTqMPSkK\ncGvNJrieT7KTQ7cWUZNYj3L3+8LiueE9Gwjm+3wDeBc42Mzam9nmwM8Jbl63Ou5+iLsf6u4DgHnA\nIODZdB4zwaTkR5hZlpltQzB360tpPuYi1p6Z/AS0Ic1/tqM0ZZx1v9+i6qa9tLgE10JmEvzF/xZr\nJ4dOF1cABcBVZlZ7L+5C4C4zawssBh5192ozu4vghz8buNLd12yUHqfGJcC0dB1z+LTcIQS/5LKB\n84DPSOMxA7cD95nZGwRnblcA75HeY66V9M+zmU0GZpjZm0AFcMpG6/UGpMmWRUQkLekSpYiIpCUF\nOBERSUsKcCIikpYU4EREJC0pwImISFpSgJNNipn1MLOImQ1sUP65mfVogf23yH4SHGM7M1tiZu+H\ns8es734GhC+qY2avRr3zlFJmto+Z3ZugzlFmNnJD9Edkfek9ONkUVRK839Pb3Vdu7M6shwHAB+7e\nKt81cvf3gCEJqu29Ifoi0hwKcLIp+hZ4gSCjw9DoDeFZzNhwhhLMbDrwavjvCeBToDfBy76vAmcQ\nvOR+nLsvDncz1sz6EkxlNczd54ezvUwhmIG/Bhjt7i+a2VigH7AdMNHdJ0X1pRcwFegClBLM4l5J\nkI6oo5nd4+7Do+p3B/4KdAa2Bv7P3S8P5808PtzPlgQTJV8S43MZYmbjw/Fc6O5PmdnuwASgI8FU\nZOPd/a4Gn9lYoBewE9AVmOLut4QTFN8B/JIg5cqD7n5T9GccnkG+CxwMFALnA18QzHWJmX0BfAnc\nHO6jCDjZ3ZfH6L/IBqVLlLKpugT4VcNLlQn0Aa4DDNgX6BGmP/o/6gfKT9x9z7DujLDsTuA+d9+b\nIJ/alKjLi+3dfdfo4Bb6X+Aud+9DMCfiowQzSlwNzIoObqGTCYJav7Cv55pZt3DbvsAJwG4EAfW4\nGOMrDvt3QXgMCM60rnf3fYHDCNLFxLI7QSDbGxhmZnsRBKmfhX3ZDzjBzH4To23b8HO8ODzWRwRZ\nGu5x9/sJJu8e7u77EATnvRrpg8gGpQAnmyR3X0GQvHJaE+5jfe/uc929BvgaeCks/4LgrKfWveEx\nngG2N7POBOlD/mxm8wjSibQhOOMBeKfhgcysI7Czuz8e7msOwVyIFmdMtwJfmtmlBAG1LcF8kRAE\nxP+6ewXwN+AXMXbxRPh1EUHmAAj+EGgfJjq9geBMLpb/C7NKlACzwv3/Apju7tXuXkaQfeCXMdrW\npllZSHCW2dAsYKaZTQQWu/u/GumDyAalACebrPAXZe2lyloRgrlCa7WJWq5osIvGskE0LK8AcoBf\nuPse7r4HwVlU7YTbq1lXdoN+EK43etk/vLx4AUHAvR5YHrWP6D5lN9L32rLoz+ARgrO9jwjmYWxM\nrP03/P/fWP9r52xs+NkD4O63E9x3XArcbGZXxumHyAajACebuksIEnluE64vB3YMZ0vvQnBvqKn+\nCGBmxwFLwrOXl4Fzw/JdgflAXmM7CM8w/2Nmx4dt+gFbEX+G+oHALe7+D4JLg90JAivAkWa2uZm1\nJ7iU+WySYxkIXO3uTxJk8cbMcmLUO87M2ppZAXAUQXaJl4HTzSzHzPIIPpdXkjxuFWEwNLN3gHx3\nv4Ng8mNdopRNggKcbNKiLlW2CdcXAf8kuEz3D9Yv7Uev8FLkSOD0sOx8oJ+ZzQf+DpyWxBOcpwIX\nmNkCYCJwfHiJsTHjgAfN7H3gTwQPwuwQbvsBeAb4EHiqQaLWeMYCb5rZBwR/CHwetc9oqwnS6bwN\njAvvo00huJT7ITCX4DLpzCSP+zrwRzM7n+DMcXo4rqHANUnuQySllE1AZCMLn6Ic4O5npGj/YwHc\nfWwq9i+yqdIZnIiIpCWdwYmISFrSGZyIiKQlBTgREUlLCnAiIpKWFOBERCQtKcCJiEha+n/1sd11\nWBOFfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2900cdb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the misclassification error for each alpha is :  [ 0.141  0.128  0.127  0.127  0.127  0.127  0.127]\n"
     ]
    }
   ],
   "source": [
    "# plot misclassification error vs alpha \n",
    "plt.plot(C_Val, MSE_avg_tf)\n",
    "\n",
    "for xy in zip(C_Val, np.round(MSE_avg_tf,3)):\n",
    "    plt.annotate('(%s, %s)' % xy, xy=xy, textcoords='data')\n",
    "\n",
    "plt.xlabel('Number of aplha points')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.title('MSE')\n",
    "plt.show()\n",
    "\n",
    "print(\"the misclassification error for each alpha is : \", np.round(MSE_avg_tf,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the Logistic Regression for C = 1.000000 is 87.513333%\n"
     ]
    }
   ],
   "source": [
    "# instantiate learning model k = optimal_k\n",
    "optimal_aplha_avg_tf=1\n",
    "log_reg_optimal_avg_tf = LogisticRegression(C=optimal_aplha_avg_tf)\n",
    "\n",
    "# fitting the model\n",
    "log_reg_optimal_avg_tf.fit(X_tr_avg_tf, y_tr_avg_tf)\n",
    "\n",
    "# predict the response\n",
    "pred_avg_tf = log_reg_optimal_avg_tf.predict(X_test_avg_tf)\n",
    "\n",
    "# evaluate accuracy\n",
    "acc_avg_tf = accuracy_score(y_test_avg_tf, pred_avg_tf) * 100\n",
    "print('\\nThe accuracy of the Logistic Regression for C = %f is %f%%' % (optimal_aplha_avg_tf, acc_avg_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch Avg TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_avg_tf_l2 = GridSearchCV(LogisticRegression(n_jobs=-1), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_avg_tf_l2.fit(X_tr_avg_tf, y_tr_avg_tf)\n",
    "print(model_avg_tf_l2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875133333333\n"
     ]
    }
   ],
   "source": [
    "print(model_avg_tf_l2.score(X_test_avg_tf, y_test_avg_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used GridSearchCV with L2 regularizer is 1 and the accuracy is 87.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_avg_tf_l1 = GridSearchCV(LogisticRegression(penalty='l1',n_jobs=-1), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_avg_tf_l1.fit(X_tr_avg_tf, y_tr_avg_tf)\n",
    "print(model_avg_tf_l1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875133333333\n"
     ]
    }
   ],
   "source": [
    "print(model_avg_tf_l1.score(X_test_avg_tf, y_test_avg_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used GridSearchCV with L1 regularizer is 1 and the accuracy is 87.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSearchCV AVG TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.90660872776219958, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "tuned_parameters = {'C': uniform.rvs(size=10)}\n",
    "model_rand_l2_avg_tf = RandomizedSearchCV(LogisticRegression(n_jobs=-1), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_rand_l2_avg_tf.fit(X_tr_avg_tf, y_tr_avg_tf)\n",
    "print(model_rand_l2_avg_tf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8751\n"
     ]
    }
   ],
   "source": [
    "print(model_rand_l2_avg_tf.score(X_test_avg_tf, y_test_avg_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used RandomSearchCV with L2 regularizer is 0.90 and the accuracy is 87.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.92224403068218885, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=-1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "tuned_parameters = {'C': uniform.rvs(size=10)}\n",
    "model_rand_l1_avg_tf = RandomizedSearchCV(LogisticRegression(penalty='l1',n_jobs=-1), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model_rand_l1_avg_tf.fit(X_tr_avg_tf, y_tr_avg_tf)\n",
    "print(model_rand_l1_avg_tf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875033333333\n"
     ]
    }
   ],
   "source": [
    "print(model_rand_l1_avg_tf.score(X_test_avg_tf, y_test_avg_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    The optimal lambda when used RandomSearchCV with L1 regularizer is 0.92 and the accuracy is 87.503%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsity with L1 Avg TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.875166666667\n",
      "sparsity 49\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "clf_1_avg_tf = LogisticRegression(C=0.1, penalty='l1');\n",
    "clf_1_avg_tf.fit(X_tr_avg_tf, y_tr_avg_tf);\n",
    "print('acc',clf_1_avg_tf.score(X_test_avg_tf,y_test_avg_tf))\n",
    "w_1_avg_tf = clf_1_avg_tf.coef_\n",
    "print('sparsity',np.count_nonzero(w_1_avg_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * The error rate is 12.5% when lambda is 0.1 and the number of non zero elements are 49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8751\n",
      "sparsity 50\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "clf_2_avg_tf = LogisticRegression(C=1, penalty='l1');\n",
    "clf_2_avg_tf.fit(X_tr_avg_tf, y_tr_avg_tf);\n",
    "print('acc',clf_2_avg_tf.score(X_test_avg_tf,y_test_avg_tf))\n",
    "w_2_avg_tf = clf_2_avg_tf.coef_\n",
    "print('sparsity',np.count_nonzero(w_2_avg_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * The error rate is 12.5% when lambda is 0.1 and the number of non zero elements are 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.874633333333\n",
      "sparsity 50\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "clf_3_avg_tf = LogisticRegression(C=100, penalty='l1');\n",
    "clf_3_avg_tf.fit(X_tr_avg_tf, y_tr_avg_tf);\n",
    "print('acc',clf_3_avg_tf.score(X_test_avg_tf,y_test_avg_tf))\n",
    "w_3_avg_tf = clf_3_avg_tf.coef_\n",
    "print('sparsity',np.count_nonzero(w_3_avg_tf))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "    * The error rate is 12.6% when lambda is 0.1 and the number of non zero elements are 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicollinearity Avg TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0989487]\n"
     ]
    }
   ],
   "source": [
    "# Adding Noise to the matrix\n",
    "mu, sigma = 0, 0.1\n",
    "s = np.random.normal(mu, sigma, 1)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_vector_avg_tf = [i * 0.05373827 for i in tfidf_sent_vectors] # adding noise to the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data set into train and test\n",
    "X_1_avg_tf_mul, X_test_avg_tf_mul, y_1_avg_tf_mul, y_test_avg_tf_mul = cross_validation.train_test_split(noise_vector_avg_tf, sample_labels, test_size=0.3, random_state=0)\n",
    "\n",
    "# split the train data set into cross validation train and cross validation test\n",
    "X_tr_avg_tf_mul, X_cv_avg_tf_mul, y_tr_avg_tf_mul, y_cv_avg_tf_mul = cross_validation.train_test_split(X_1_avg_tf_mul, y_1_avg_tf_mul, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "X_tr_avg_tf_mul = pd.DataFrame(data=X_tr_avg_tf_mul)\n",
    "X_tr_avg_tf_mul = X_tr_avg_tf_mul.fillna(X_tr_avg_tf_mul.mean())\n",
    "print(X_tr_avg_tf_mul.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the Logistic Regression for C = 1.000000 is 86.883333%\n"
     ]
    }
   ],
   "source": [
    "# instantiate learning model k = optimal_k\n",
    "optimal_aplha_avg_tf=1\n",
    "log_reg_optimal_avg_tf_mul = LogisticRegression(C=optimal_aplha_avg_tf)\n",
    "\n",
    "# fitting the model\n",
    "log_reg_optimal_avg_tf_mul.fit(X_tr_avg_tf_mul, y_tr_avg_tf_mul)\n",
    "\n",
    "# predict the response\n",
    "pred_avg_tf_mul = log_reg_optimal_avg_tf_mul.predict(X_test_avg_tf_mul)\n",
    "\n",
    "# evaluate accuracy\n",
    "acc_avg_tf_mul = accuracy_score(y_test_avg_tf_mul, pred_avg_tf_mul) * 100\n",
    "print('\\nThe accuracy of the Logistic Regression for C = %f is %f%%' % (optimal_aplha_avg_tf, acc_avg_tf_mul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50)\n",
      "[[ -1.19565116   0.41103293   7.06564944   0.81493603   4.09574637\n",
      "    8.3037898   -0.62326072   9.04790841  -4.84543772  12.82962211\n",
      "   -0.3542967    2.34126327   5.24958626  -6.44254015   3.92103852\n",
      "   -5.31366544  -6.31757029   5.59002471  -5.46454393  -3.67195957\n",
      "   -5.5860038    0.75604886   3.48335462   5.6910924   -9.00270042\n",
      "   -2.88634042 -11.47374511  -2.0065696    3.0168884    1.35561793\n",
      "   -5.11312785   0.83582565  -4.42825096  -4.3416799   -7.86835189\n",
      "   -4.25957792  -2.57486799  -8.77514814   0.90481247  -5.15872323\n",
      "   -7.36369565  -3.53351386  -7.10148978   6.70523092  -2.65867674\n",
      "   -5.36206246  -4.50533019  13.01652552  11.6936484   -7.60582925]]\n"
     ]
    }
   ],
   "source": [
    "weight_multi_avg_tf = log_reg_optimal_avg_tf_mul.coef_ # weights with  noise\n",
    "print(weight_multi_avg_tf.shape)\n",
    "print(weight_multi_avg_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50)\n",
      "[[-0.35042208 -0.76886267  0.74715693 -0.38517252  1.19609365  0.17724906\n",
      "  -1.31677478 -0.14080108 -1.4031288   0.88528776  0.07660364 -0.46738738\n",
      "   0.48238135 -0.89823943  2.21907947 -0.62050105 -0.05171797  1.03358181\n",
      "  -0.48203131 -1.35859216 -0.05002123 -0.57944756  0.62722423  1.08151499\n",
      "  -0.56132151 -1.00326308 -0.84906387  0.97961423  0.51344209  0.1636517\n",
      "  -0.43314184  0.57898731  0.3104145   0.4595395  -0.56819258 -0.29638326\n",
      "   0.85111512  0.01564376  0.45161809 -1.16639902 -0.82420767 -0.01403417\n",
      "   0.71379222  0.7425713  -0.90477033 -0.62315891 -0.97662008  1.85285493\n",
      "   0.50334442 -1.47846186]]\n"
     ]
    }
   ],
   "source": [
    "# Weights from the original matrix which is not added any noise\n",
    "original_weights_avg_tf = log_reg_optimal_avg_tf.coef_ # original weights with no noise\n",
    "print(original_weights_avg_tf.shape)\n",
    "print(original_weights_avg_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.84522908   1.1798956    6.31849251   1.20010855   2.89965272\n",
      "   8.12654075   0.69351406   9.1887095   -3.44230892  11.94433436\n",
      "  -0.43090034   2.80865065   4.76720491  -5.54430072   1.70195905\n",
      "  -4.69316439  -6.26585231   4.5564429   -4.98251261  -2.31336741]\n"
     ]
    }
   ],
   "source": [
    "diffs_avg_tf = weight_multi_avg_tf - original_weights_avg_tf\n",
    "print(diffs_avg_tf.flatten()[:20])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Report:\n",
    "   * I observe the some high difference between the noised and original weights. There is a multicollinearity exists among the features."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Final Report:\n",
    "    * There is no multicollinearity for Bag of Words and TF-IDF because these both are vectorizations but when I implemented Avg W2V and Avg TF-IDF there exists multicollinearity because these are embeddings and we find the similarity between the words only without providing the sentence in which they occur.\n",
    "    * Tested multicollinearity by adding noise to the original weights and compared with weights + noise and original weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
